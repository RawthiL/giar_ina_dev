{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labeled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, InceptionV3, DenseNet121, MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../../models/clustering_model.pkl\"\n",
    "IMAGE_PATH = \"/content/drive/My Drive/Investigacion/UTN/GIAR/Dataset/cropped_cells_original\"\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    "OUTPUT_PATH = f\"/content/drive/My Drive/Investigacion/UTN/GIAR/Dataset/clustering/{MODEL}_{METHOD}_v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_file_paths(folder_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Gets a list of relative paths to all files within a given folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of relative file paths.\n",
    "    \"\"\"\n",
    "\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "def load_image (x):\n",
    "    if MODEL == \"AutoEncoder\":\n",
    "        return cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        return cv2.imread(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get cluster representatrives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(get_relative_file_paths(IMAGE_PATH))\n",
    "\n",
    "images = process_map(\n",
    "                load_image,\n",
    "                image_paths,\n",
    "                total=len(image_paths),\n",
    "                max_workers=16,\n",
    "                chunksize=32,\n",
    "            )\n",
    "\n",
    "resized_images = [cv2.resize(image, INPUT_SHAPE[0:2]) for image in images]\n",
    "resized_images = np.array(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_loaded = joblib.load('kmeans_model.pkl')\n",
    "seleccted_class = clustering_loaded.labels_\n",
    "\n",
    "NUM_CLUSTERS = len(np.unique(seleccted_class))\n",
    "GRID_SIZE = 8\n",
    "NUM_SHOW = GRID_SIZE*GRID_SIZE\n",
    "\n",
    "rep_images =[[] for _ in range(NUM_CLUSTERS)]\n",
    "for cluster in range(NUM_CLUSTERS):\n",
    "    for idx, label in enumerate(seleccted_class):\n",
    "        if label >= 0:\n",
    "            if len(rep_images[label]) < NUM_SHOW:\n",
    "                rep_images[label].append(resized_images[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep_idx, rep_list in enumerate(rep_images):\n",
    "\n",
    "    plt.figure()\n",
    "    n = 1\n",
    "    for image in rep_list:\n",
    "        plt.subplot(GRID_SIZE,GRID_SIZE,n)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(False)\n",
    "        n+=1\n",
    "    plt.suptitle(f\"Cluster {rep_idx}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually pick one\n",
    "CELL_CLUSTERS = [2,5,13]\n",
    "NOT_CLUSTERS=[1,6,7,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.7\n",
    "realization_samples = dict()\n",
    "for file in os.listdir(IMAGE_PATH):\n",
    "    base, realiz, *_ = file.split(\"_\")\n",
    "    if base not in realization_samples.keys():\n",
    "        realization_samples[base]  = set()\n",
    "    realization_samples[base].add(realiz)\n",
    "\n",
    "\n",
    "train_samples = dict()\n",
    "validation_samples = dict()\n",
    "for key in realization_samples.keys():\n",
    "    images_here = len(realization_samples[key])\n",
    "\n",
    "    train_images_here = int(np.floor(images_here*SPLIT))\n",
    "    this_train_sample = np.random.choice(list(realization_samples[key]), train_images_here, replace=False)\n",
    "    if base not in train_samples.keys():\n",
    "        train_samples[key]  = list()\n",
    "        validation_samples[key]  = list()\n",
    "    train_samples[key] = this_train_sample\n",
    "    validation_samples[key] = [a for a in list(realization_samples[key]) if a not in this_train_sample]\n",
    "\n",
    "print(\"Train:\")\n",
    "for key in train_samples.keys():\n",
    "    print(key, len(train_samples[key]))\n",
    "print(\"Validation:\")\n",
    "for key in validation_samples.keys():\n",
    "    print(key, len(validation_samples[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class = 3500\n",
    "\n",
    "# Random Shuffle\n",
    "indices = np.arange(seleccted_class.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "seleccted_class_shuffle = seleccted_class[indices]\n",
    "image_paths_shuffle = np.array(image_paths)[indices]\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    shutil.rmtree(OUTPUT_PATH)\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, 'train', \"not\"))\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, 'train', \"cells\"))\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, 'validation', \"not\"))\n",
    "os.makedirs(os.path.join(OUTPUT_PATH, 'validation', \"cells\"))\n",
    "\n",
    "for idx, cluster in enumerate(seleccted_class_shuffle):\n",
    "    if cluster >= 0:\n",
    "        if cluster in CELL_CLUSTERS:\n",
    "            folder = \"cells\"\n",
    "        elif cluster in NOT_CLUSTERS:\n",
    "            folder = \"not\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        file = image_paths_shuffle[idx]\n",
    "        img_name = os.path.basename(file)\n",
    "        base, realiz, *_ = img_name.split(\"_\")\n",
    "\n",
    "        if realiz in train_samples[base]:\n",
    "            split = \"train\"\n",
    "        else:\n",
    "            split = \"validation\"\n",
    "\n",
    "        if len(os.listdir(os.path.join(OUTPUT_PATH, split,folder))) >= max_class:\n",
    "            continue\n",
    "\n",
    "\n",
    "        shutil.copyfile(file, os.path.join(OUTPUT_PATH, split, folder, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder_agglomerative_v0\n"
     ]
    }
   ],
   "source": [
    "print(os.path.basename(OUTPUT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "3500\n",
      "3500\n",
      "2714\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(os.path.join(OUTPUT_PATH, \"train\", \"not\"))))\n",
    "print(len(os.listdir(os.path.join(OUTPUT_PATH, \"train\", \"cells\"))))\n",
    "print(len(os.listdir(os.path.join(OUTPUT_PATH, \"validation\", \"not\"))))\n",
    "print(len(os.listdir(os.path.join(OUTPUT_PATH, \"validation\", \"cells\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
