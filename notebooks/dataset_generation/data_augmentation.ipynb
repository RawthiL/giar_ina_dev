{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c7043ba",
      "metadata": {},
      "source": [
        "# data_augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f3f551a",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33103c26-2088-4b03-a469-612446e7f941",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33103c26-2088-4b03-a469-612446e7f941",
        "outputId": "d559f8dc-755d-4d39-f5d3-9b66f02a9a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import OneClassSVM\n",
        "import random\n",
        "from itertools import product\n",
        "import skimage.io\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "import glob\n",
        "import cv2\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UC1Q9vYyLk1O",
      "metadata": {
        "id": "UC1Q9vYyLk1O"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4QgXs129EDHT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "4QgXs129EDHT",
        "outputId": "787e33ee-4e6c-47d1-8d13-955387120206"
      },
      "outputs": [],
      "source": [
        "# Función para añadir ruido a la imagen\n",
        "def add_noise(image):\n",
        "    np_image = np.array(image)\n",
        "    ruido = np.random.normal(10, 25, np_image.shape).astype(np.int32)  # Nivel de ruido\n",
        "    noisy_image = np.clip(np_image + ruido, 0, 255).astype(np.uint8)  # Asegurar valores válidos\n",
        "    return Image.fromarray(noisy_image)\n",
        "\n",
        "# Función para deformación elástica\n",
        "def elastic_transform(image):\n",
        "    \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
        "    \"\"\"\n",
        "    image = np.array(image)\n",
        "    alpha = image.shape[1] * 2\n",
        "    sigma = image.shape[1] * 0.08\n",
        "    alpha_affine = image.shape[1] * 0.08\n",
        "\n",
        "    shape = image.shape\n",
        "    shape_size = shape[:2]\n",
        "    random_state = np.random.RandomState(None)\n",
        "\n",
        "    # Random affine\n",
        "    center_square = np.float32(shape_size) // 2\n",
        "    square_size = min(shape_size) // 3\n",
        "    pts1 = np.float32([center_square + square_size,\n",
        "                       [center_square[0]+square_size, center_square[1]-square_size],\n",
        "                       center_square - square_size])\n",
        "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "    M = cv2.getAffineTransform(pts1, pts2)\n",
        "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    # Elastic deformation (Gaussian noise)\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dz = np.zeros_like(dx)\n",
        "\n",
        "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "    # Apply elastic deformation\n",
        "    deformed_image = map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
        "\n",
        "    # Convert back to PIL Image\n",
        "    deformed_image_pil = Image.fromarray(deformed_image.astype(np.uint8))\n",
        "\n",
        "    return deformed_image_pil\n",
        "\n",
        "# Aplicar todas las transformaciones juntas\n",
        "def augment_image(image):\n",
        "    augmented_image = image\n",
        "\n",
        "    # 1. Volteo horizontal\n",
        "    augmented_image = ImageOps.mirror(augmented_image)\n",
        "\n",
        "    # 2. Volteo vertical\n",
        "    augmented_image = ImageOps.flip(augmented_image)\n",
        "\n",
        "    # 3. Ajuste de brillo (ajuste más sutil)\n",
        "    enhancer = ImageEnhance.Brightness(augmented_image)\n",
        "    brightness_factor = random.uniform(0.5, 1.5)  # Antes: (0.6, 1.8)\n",
        "    augmented_image = enhancer.enhance(0.5)\n",
        "\n",
        "    # 4. Ajuste de contraste (ajuste más sutil)\n",
        "    enhancer = ImageEnhance.Contrast(augmented_image)\n",
        "    contrast_factor = random.uniform(0.5, 1.5)  # Antes: (0.6, 1.8)\n",
        "    augmented_image = enhancer.enhance(contrast_factor)\n",
        "\n",
        "     # 5. Cambio de saturación (ajuste más sutil)\n",
        "    enhancer = ImageEnhance.Color(augmented_image)\n",
        "    saturation_factor = random.uniform(0.5, 1.5)  # Ajuste sutil\n",
        "    augmented_image = enhancer.enhance(saturation_factor)\n",
        "\n",
        "    # 6. Añadir ruido (menos probabilidad de aplicarlo)\n",
        "    #if random.random() < 0.5:  # 50% de probabilidad\n",
        "    augmented_image = add_noise(augmented_image)\n",
        "\n",
        "    # 7. Aplicar deformación elástica (probabilidad de aplicarla)\n",
        "    #if random.random() < 0.:  # 30% de probabilidad\n",
        "    augmented_image = elastic_transform(augmented_image)\n",
        "\n",
        "    return augmented_image\n",
        "\n",
        "def generar_nombre(imagen_original):\n",
        "    nombre, ext = os.path.splitext(imagen_original)\n",
        "    return f\"{nombre}_aug{ext}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e10be739-aab1-458e-baa1-99b9beb253b2",
      "metadata": {
        "id": "e10be739-aab1-458e-baa1-99b9beb253b2"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4030b97-dd09-4f58-a842-8e7dfe47ebea",
      "metadata": {
        "id": "d4030b97-dd09-4f58-a842-8e7dfe47ebea"
      },
      "outputs": [],
      "source": [
        "# Directorio del dataset\n",
        "dataset_path = \"/content/drive/My Drive/Investigacion/UTN/GIAR/Dataset/clustering/AutoEncoder_agglomerative_v0/train/not\"\n",
        "save_path = dataset_path\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise FileNotFoundError(f\"El directorio {dataset_path} no existe.\")\n",
        "\n",
        "imagenes_originales = [\n",
        "    file_name for file_name in os.listdir(dataset_path)\n",
        "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "# Determinar la cantidad máxima de imágenes aumentadas\n",
        "cantidad_aumentadas = int(len(imagenes_originales) * 1)  # Hasta el 70%\n",
        "contador = 0\n",
        "\n",
        "\n",
        "for file_name in random.sample(imagenes_originales, cantidad_aumentadas):  # Selección aleatoria\n",
        "    file_path = os.path.join(dataset_path, file_name)\n",
        "\n",
        "    with Image.open(file_path) as img:\n",
        "        # Aplicar augmentations\n",
        "        augmented_image = augment_image(img)\n",
        "\n",
        "        # Guardar la imagen\n",
        "        nuevo_nombre = generar_nombre(file_name)\n",
        "        nuevo_path = os.path.join(save_path, nuevo_nombre)\n",
        "        augmented_image.save(nuevo_path)\n",
        "        contador += 1\n",
        "\n",
        "print(f\"Se han generado {contador} imágenes aumentadas en {save_path}.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
