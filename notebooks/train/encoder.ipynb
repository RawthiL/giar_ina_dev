{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "This notebook trains an autoencoder with all the cropped cells generated in crop_cell_segmentation.ipynb which encoder will be later used in supervised.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0owgoD05MCtC",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47660,
     "status": "ok",
     "timestamp": 1742655088761,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "Qh0_ITlO0ATe",
    "outputId": "ac59cd97-38c4-4d49-869f-254de62efee6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model, clone_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxhuRObFMCtF"
   },
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742655287826,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "LFNn7w4kMCtF"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../../\")\n",
    "from config import CROPPED_PATH, MODELS_PATH\n",
    "\n",
    "# Paths\n",
    "CROPS_PATH = os.path.join(CROPPED_PATH, 'ina', 'images')\n",
    "ENCODER_PATH = os.path.join(MODELS_PATH, 'encoder', 'encoder_SSIM_MAE_Bparams.keras')\n",
    "\n",
    "# Configuration\n",
    "SHAPE = (128,128,1)\n",
    "BATCH_SIZE = 300\n",
    "VALIDITAION_SPLIT = 0.2\n",
    "ON_RAM = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1fkxwTnMCtG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 63306,
     "status": "ok",
     "timestamp": 1742655356128,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "aVEznQSHMCtG"
   },
   "outputs": [],
   "source": [
    "\n",
    "if ON_RAM:\n",
    "\n",
    "    images = np.zeros((len(os.listdir(CROPS_PATH)), SHAPE[0], SHAPE[1]))\n",
    "    for idx, file in tqdm(enumerate(os.listdir(CROPS_PATH)), total=len(os.listdir(CROPS_PATH))):\n",
    "        image = cv2.imread(os.path.join(CROPS_PATH, file), cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (SHAPE[0], SHAPE[1]))\n",
    "        image = np.array(image) #\n",
    "\n",
    "        images[idx, : ,:] = image\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test = train_test_split(images, test_size=VALIDITAION_SPLIT, random_state=42)\n",
    "    x_train.shape\n",
    "\n",
    "else:\n",
    "\n",
    "    image_paths = os.listdir(CROPS_PATH)\n",
    "\n",
    "    # Train / val split\n",
    "    val_size = int(0.2 * len(image_paths))  # 20% para validación\n",
    "    train_paths = image_paths[:-val_size]\n",
    "    val_paths = image_paths[-val_size:]\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices(val_paths)\n",
    "\n",
    "    # Load & augmentation\n",
    "    def load_image(path):\n",
    "\n",
    "      image = tf.io.read_file(path)\n",
    "      image = tf.image.decode_png(image, channels=1)  # Escala de grises\n",
    "      image = tf.image.resize(image, (SHAPE[0], SHAPE[1]))\n",
    "      # Augmentación\n",
    "\n",
    "      image = tf.image.random_flip_left_right(image)\n",
    "      image = tf.image.random_flip_up_down(image)\n",
    "      image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "      image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "      scales = tf.random.uniform([], 0.8, 1.0)\n",
    "      crop_size = tf.cast(scales * SHAPE[0], tf.int32)\n",
    "      image = tf.image.random_crop(image, size=[crop_size, crop_size, 1])\n",
    "      image = tf.image.resize(image, (SHAPE[0], SHAPE[1]))\n",
    "      # Normalize [0, 1]\n",
    "      image = tf.cast(image, tf.float32) / 255.0\n",
    "      return image,image\n",
    "\n",
    "    # Train dataset\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "    train_dataset = train_dataset.map(lambda x: load_image(x), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "\n",
    "    # Val dataset\n",
    "    validation_dataset = val_dataset.map(lambda x: load_image(x), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
    "    validation_dataset = validation_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.repeat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742655356133,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "t_HJo_tvWeX_",
    "outputId": "838ce3ee-f97c-47fd-ef8b-31b049c62b0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42915"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnTJ7GglMu5S"
   },
   "source": [
    "### Weigthed Loss: SSIM + MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742655356135,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "S8sZioOzMSCG"
   },
   "outputs": [],
   "source": [
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, y, z, name=\"custom_loss\"):\n",
    "        super().__init__(name=name)\n",
    "        # Weights\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "        #MAE\n",
    "        self.mae_loss_fn = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    # SSIM loss\n",
    "    def ssim_loss(self, y_true, y_pred):\n",
    "\n",
    "        ssim = (1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))) / 2\n",
    "        return ssim\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "\n",
    "        mae_loss = self.mae_loss_fn(y_true, y_pred)\n",
    "        ssim = self.ssim_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "        return  self.y * mae_loss + self.z * ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPMSP9GuMCtH"
   },
   "source": [
    "### AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1374,
     "status": "ok",
     "timestamp": 1742655357510,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "nfrJL1wzFywX"
   },
   "outputs": [],
   "source": [
    "kernel_size = (4,4)\n",
    "filter = 32\n",
    "\n",
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(128, 128, 1))\n",
    "\n",
    "x = encoder_input\n",
    "\n",
    "x = layers.Rescaling(1.0 / 255.0)(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(filter, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(filter//2, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(filter//4, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(filter//8, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(filter//16, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPool2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "encoder_output = x\n",
    "\n",
    "\n",
    "encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "# Decoder\n",
    "\n",
    "decoder_input = layers.Input(shape=[encoder.output_shape[-1]])\n",
    "\n",
    "x = decoder_input\n",
    "\n",
    "x = layers.Reshape((2*filter//16, 2*filter//16, filter//16))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(filter//16, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(filter//8, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(filter//4, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(filter//2, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(filter, kernel_size, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(1, kernel_size, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "#x = layers.Rescaling(255.0)(x)\n",
    "\n",
    "decoder_output = x\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "# Build the autoencoder model\n",
    "# autoencoder = Model(encoder_input, decoder_output)\n",
    "autoencoder = Sequential([\n",
    "    encoder,\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742655357550,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "cjtXLfATMCtI",
    "outputId": "25d9c732-e674-4116-d329-acbaf1087c4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m8,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │           \u001b[38;5;34m516\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │            \u001b[38;5;34m16\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │           \u001b[38;5;34m130\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m8\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,702</span> (45.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,702\u001b[0m (45.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,578</span> (45.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,578\u001b[0m (45.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> (496.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m124\u001b[0m (496.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1742655357584,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "acjm1IOuMCtI",
    "outputId": "162b1eeb-a734-4dbb-aa6e-7c4089cfc003"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │            \u001b[38;5;34m66\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m8\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │           \u001b[38;5;34m132\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)        │            \u001b[38;5;34m16\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │           \u001b[38;5;34m520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_2 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m2,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_3 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_4 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,767</span> (45.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,767\u001b[0m (45.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,643</span> (45.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,643\u001b[0m (45.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> (496.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m124\u001b[0m (496.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742655357592,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "xlgc2kcn4RmJ",
    "outputId": "fec8b743-24dc-4e1f-9669-ce5753837e0a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,702</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,767</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ functional (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m11,702\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │        \u001b[38;5;34m11,767\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,469</span> (91.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,469\u001b[0m (91.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,221</span> (90.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,221\u001b[0m (90.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">248</span> (992.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m248\u001b[0m (992.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary of the model\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBIBVikgMCtI"
   },
   "source": [
    "### Compile & fit - Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1742655357624,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "0LaIhScPbQif",
    "outputId": "fb8a2710-cb3a-4788-f14d-880fdd15b1e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations:  19\n",
      "Combination 1:  (0.25, 0.7500000000000001)\n",
      "Combination 2:  (0.37500000000000006, 0.625)\n",
      "Combination 3:  (0.3333333333333333, 0.6666666666666666)\n",
      "Combination 4:  (0.7142857142857143, 0.28571428571428575)\n",
      "Combination 5:  (0.4285714285714286, 0.5714285714285714)\n",
      "Combination 6:  (0.4444444444444445, 0.5555555555555556)\n",
      "Combination 7:  (0.5555555555555556, 0.4444444444444445)\n",
      "Combination 8:  (0.7500000000000001, 0.25)\n",
      "Combination 9:  (0.5, 0.5)\n",
      "Combination 10:  (0.28571428571428575, 0.7142857142857143)\n",
      "Combination 11:  (0.5714285714285714, 0.4285714285714286)\n",
      "Combination 12:  (0.625, 0.37500000000000006)\n",
      "Combination 13:  (0.8333333333333334, 0.16666666666666669)\n",
      "Combination 14:  (0.6000000000000001, 0.4)\n",
      "Combination 15:  (0.6666666666666666, 0.3333333333333333)\n",
      "Combination 16:  (0.2, 0.8)\n",
      "Combination 17:  (0.4, 0.6000000000000001)\n",
      "Combination 18:  (0.8, 0.2)\n",
      "Combination 19:  (0.16666666666666669, 0.8333333333333334)\n"
     ]
    }
   ],
   "source": [
    "# Weight range from 0.2 to 1\n",
    "y_values = np.arange(0.2, 1.2, 0.2)\n",
    "z_values = np.arange(0.2, 1.2, 0.2)\n",
    "\n",
    "# Combinations of weights\n",
    "param_combinations = list(itertools.product(y_values,z_values))\n",
    "\n",
    "random.seed(34)\n",
    "random.shuffle(param_combinations)\n",
    "\n",
    "# Normalize weights ---> y + z = 1\n",
    "def normalize_weights(weights):\n",
    "    total_sum = sum(weights)\n",
    "    return tuple(weight / total_sum for weight in weights)\n",
    "\n",
    "param_combinations = [normalize_weights(weights) for weights in param_combinations]\n",
    "param_combinations =set(param_combinations) #delete duplicate\n",
    "print(\"Total combinations: \", len(param_combinations))\n",
    "for i,combination in enumerate(param_combinations):\n",
    "    print(f\"Combination {i+1}: \", tuple(map(float, combination)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18680609,
     "status": "ok",
     "timestamp": 1742674038234,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "oKOSGnKIa0bh",
    "outputId": "ff268659-42ef-4a74-8456-99862070876f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 527ms/step - loss: 0.2713 - val_loss: 0.2570\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 515ms/step - loss: 0.2291 - val_loss: 0.2496\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.2255 - val_loss: 0.2476\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.2224 - val_loss: 0.2387\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 524ms/step - loss: 0.2218 - val_loss: 0.2141\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.2204 - val_loss: 0.2028\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.2196 - val_loss: 0.1983\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 513ms/step - loss: 0.2189 - val_loss: 0.2089\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.2182 - val_loss: 0.2405\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.2184 - val_loss: 0.2030\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.2173 - val_loss: 0.2485\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.2171 - val_loss: 0.2054\n",
      "Params (np.float64(0.25), np.float64(0.7500000000000001)) -> Val Loss: 0.19833260774612427\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 516ms/step - loss: 0.2488 - val_loss: 0.2490\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 515ms/step - loss: 0.2057 - val_loss: 0.2392\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.2007 - val_loss: 0.2384\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1971 - val_loss: 0.2318\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1957 - val_loss: 0.1968\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1943 - val_loss: 0.1867\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 513ms/step - loss: 0.1946 - val_loss: 0.3805\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1934 - val_loss: 0.1869\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1920 - val_loss: 0.4025\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1923 - val_loss: 0.4151\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.1918 - val_loss: 0.1828\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1913 - val_loss: 0.2434\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1915 - val_loss: 0.2024\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1913 - val_loss: 0.3894\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1906 - val_loss: 0.2575\n",
      "Epoch 16/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1899 - val_loss: 0.2373\n",
      "Params (np.float64(0.37500000000000006), np.float64(0.625)) -> Val Loss: 0.18283335864543915\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 516ms/step - loss: 0.2692 - val_loss: 0.2476\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 516ms/step - loss: 0.2203 - val_loss: 0.2514\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 534ms/step - loss: 0.2135 - val_loss: 0.2670\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.2100 - val_loss: 0.3074\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.2078 - val_loss: 0.3007\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.2076 - val_loss: 0.3142\n",
      "Params (np.float64(0.3333333333333333), np.float64(0.6666666666666666)) -> Val Loss: 0.2475825697183609\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 517ms/step - loss: 0.1868 - val_loss: 0.2189\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 514ms/step - loss: 0.1435 - val_loss: 0.2183\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 534ms/step - loss: 0.1394 - val_loss: 0.2234\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1353 - val_loss: 0.2136\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 525ms/step - loss: 0.1321 - val_loss: 0.2432\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1304 - val_loss: 0.2837\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1302 - val_loss: 0.3905\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1296 - val_loss: 0.3478\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1285 - val_loss: 0.4074\n",
      "Params (np.float64(0.7142857142857143), np.float64(0.28571428571428575)) -> Val Loss: 0.21361038088798523\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 519ms/step - loss: 0.2485 - val_loss: 0.2434\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 511ms/step - loss: 0.1997 - val_loss: 0.2394\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 534ms/step - loss: 0.1928 - val_loss: 0.2424\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 530ms/step - loss: 0.1895 - val_loss: 0.2615\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1870 - val_loss: 0.3145\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1859 - val_loss: 0.3621\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1851 - val_loss: 0.3341\n",
      "Params (np.float64(0.4285714285714286), np.float64(0.5714285714285714)) -> Val Loss: 0.23942062258720398\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 517ms/step - loss: 0.2511 - val_loss: 0.2378\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 513ms/step - loss: 0.1925 - val_loss: 0.2366\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 531ms/step - loss: 0.1880 - val_loss: 0.2310\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 533ms/step - loss: 0.1854 - val_loss: 0.2325\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.1847 - val_loss: 0.2544\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1837 - val_loss: 0.1786\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 525ms/step - loss: 0.1833 - val_loss: 0.3108\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.1824 - val_loss: 0.3578\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1814 - val_loss: 0.2806\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1819 - val_loss: 0.3223\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1820 - val_loss: 0.3619\n",
      "Params (np.float64(0.4444444444444445), np.float64(0.5555555555555556)) -> Val Loss: 0.17858673632144928\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 522ms/step - loss: 0.2166 - val_loss: 0.2288\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 514ms/step - loss: 0.1747 - val_loss: 0.2300\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.1667 - val_loss: 0.2236\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 531ms/step - loss: 0.1634 - val_loss: 0.2074\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.1618 - val_loss: 0.1830\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1603 - val_loss: 0.1779\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1596 - val_loss: 0.1705\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1587 - val_loss: 0.1699\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1572 - val_loss: 0.1681\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1572 - val_loss: 0.1795\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1569 - val_loss: 0.1901\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1567 - val_loss: 0.1846\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.1562 - val_loss: 0.2305\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1563 - val_loss: 0.3215\n",
      "Params (np.float64(0.5555555555555556), np.float64(0.4444444444444445)) -> Val Loss: 0.16814495623111725\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 514ms/step - loss: 0.1910 - val_loss: 0.2173\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 512ms/step - loss: 0.1377 - val_loss: 0.2488\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.1295 - val_loss: 0.2408\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1261 - val_loss: 0.2905\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1238 - val_loss: 0.1763\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1222 - val_loss: 0.1265\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1212 - val_loss: 0.1326\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.1210 - val_loss: 0.3415\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1205 - val_loss: 0.1383\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1203 - val_loss: 0.1400\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1201 - val_loss: 0.1284\n",
      "Params (np.float64(0.7500000000000001), np.float64(0.25)) -> Val Loss: 0.12652172148227692\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 515ms/step - loss: 0.2393 - val_loss: 0.2486\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 516ms/step - loss: 0.1821 - val_loss: 0.2412\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1761 - val_loss: 0.2428\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1734 - val_loss: 0.2316\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1722 - val_loss: 0.2616\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1714 - val_loss: 0.2435\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 513ms/step - loss: 0.1704 - val_loss: 0.2085\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1693 - val_loss: 0.3706\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1691 - val_loss: 0.1985\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1693 - val_loss: 0.3063\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1686 - val_loss: 0.3787\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1685 - val_loss: 0.2183\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1679 - val_loss: 0.4148\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1678 - val_loss: 0.1602\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1676 - val_loss: 0.2924\n",
      "Epoch 16/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1674 - val_loss: 0.2405\n",
      "Epoch 17/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1674 - val_loss: 0.3717\n",
      "Epoch 18/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1676 - val_loss: 0.2309\n",
      "Epoch 19/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1664 - val_loss: 0.3750\n",
      "Params (np.float64(0.5), np.float64(0.5)) -> Val Loss: 0.1601509004831314\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 517ms/step - loss: 0.2746 - val_loss: 0.2476\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 515ms/step - loss: 0.2253 - val_loss: 0.2494\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.2189 - val_loss: 0.2453\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 531ms/step - loss: 0.2168 - val_loss: 0.2350\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.2149 - val_loss: 0.2124\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.2131 - val_loss: 0.2121\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.2134 - val_loss: 0.2066\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.2128 - val_loss: 0.2103\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.2115 - val_loss: 0.2196\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 512ms/step - loss: 0.2108 - val_loss: 0.1948\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.2112 - val_loss: 0.2146\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.2101 - val_loss: 0.3389\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.2107 - val_loss: 0.2318\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.2098 - val_loss: 0.1912\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.2098 - val_loss: 0.1916\n",
      "Epoch 16/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.2087 - val_loss: 0.2409\n",
      "Epoch 17/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.2097 - val_loss: 0.2031\n",
      "Epoch 18/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.2089 - val_loss: 0.2001\n",
      "Epoch 19/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.2092 - val_loss: 0.2032\n",
      "Params (np.float64(0.28571428571428575), np.float64(0.7142857142857143)) -> Val Loss: 0.19124364852905273\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 514ms/step - loss: 0.2254 - val_loss: 0.2282\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 514ms/step - loss: 0.1713 - val_loss: 0.2273\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 530ms/step - loss: 0.1654 - val_loss: 0.2240\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.1615 - val_loss: 0.2257\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.1596 - val_loss: 0.1724\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1583 - val_loss: 0.1526\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.1565 - val_loss: 0.1481\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 523ms/step - loss: 0.1561 - val_loss: 0.3695\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1554 - val_loss: 0.2604\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1541 - val_loss: 0.3866\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1535 - val_loss: 0.1634\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1526 - val_loss: 0.3867\n",
      "Params (np.float64(0.5714285714285714), np.float64(0.4285714285714286)) -> Val Loss: 0.148058220744133\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 519ms/step - loss: 0.2203 - val_loss: 0.2281\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 519ms/step - loss: 0.1627 - val_loss: 0.2244\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 534ms/step - loss: 0.1544 - val_loss: 0.2200\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1520 - val_loss: 0.2019\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.1495 - val_loss: 0.1682\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1491 - val_loss: 0.1875\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 523ms/step - loss: 0.1479 - val_loss: 0.1907\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1473 - val_loss: 0.1622\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.1473 - val_loss: 0.3827\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.1469 - val_loss: 0.2177\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1468 - val_loss: 0.2294\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1465 - val_loss: 0.1524\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1455 - val_loss: 0.1454\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1452 - val_loss: 0.1564\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1458 - val_loss: 0.1449\n",
      "Epoch 16/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1450 - val_loss: 0.1368\n",
      "Epoch 17/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1442 - val_loss: 0.3984\n",
      "Epoch 18/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1463 - val_loss: 0.1594\n",
      "Epoch 19/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 524ms/step - loss: 0.1448 - val_loss: 0.1411\n",
      "Epoch 20/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1440 - val_loss: 0.1433\n",
      "Params (np.float64(0.625), np.float64(0.37500000000000006)) -> Val Loss: 0.13680869340896606\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 518ms/step - loss: 0.1787 - val_loss: 0.2106\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 517ms/step - loss: 0.1221 - val_loss: 0.2106\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 531ms/step - loss: 0.1136 - val_loss: 0.2096\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 567ms/step - loss: 0.1091 - val_loss: 0.2092\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 492ms/step - loss: 0.1074 - val_loss: 0.1572\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.1075 - val_loss: 0.1067\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1049 - val_loss: 0.1036\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1045 - val_loss: 0.1280\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.1039 - val_loss: 0.1213\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1032 - val_loss: 0.1331\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1029 - val_loss: 0.1215\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1022 - val_loss: 0.1221\n",
      "Params (np.float64(0.8333333333333334), np.float64(0.16666666666666669)) -> Val Loss: 0.10360830277204514\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 516ms/step - loss: 0.2180 - val_loss: 0.2399\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 516ms/step - loss: 0.1679 - val_loss: 0.3213\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1593 - val_loss: 0.3477\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.1562 - val_loss: 0.3030\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1536 - val_loss: 0.2485\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1527 - val_loss: 0.2567\n",
      "Params (np.float64(0.6000000000000001), np.float64(0.4)) -> Val Loss: 0.23988264799118042\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 519ms/step - loss: 0.1939 - val_loss: 0.2381\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 515ms/step - loss: 0.1490 - val_loss: 0.2568\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 533ms/step - loss: 0.1420 - val_loss: 0.2157\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 529ms/step - loss: 0.1407 - val_loss: 0.2898\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1387 - val_loss: 0.3645\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 523ms/step - loss: 0.1375 - val_loss: 0.1764\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1373 - val_loss: 0.1842\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1374 - val_loss: 0.1738\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1351 - val_loss: 0.1983\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1343 - val_loss: 0.2043\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1347 - val_loss: 0.1536\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1336 - val_loss: 0.2471\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1322 - val_loss: 0.1785\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1322 - val_loss: 0.1708\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1320 - val_loss: 0.1531\n",
      "Epoch 16/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1313 - val_loss: 0.2166\n",
      "Epoch 17/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1307 - val_loss: 0.1623\n",
      "Epoch 18/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1316 - val_loss: 0.1299\n",
      "Epoch 19/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.1303 - val_loss: 0.1343\n",
      "Epoch 20/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1306 - val_loss: 0.1390\n",
      "Params (np.float64(0.6666666666666666), np.float64(0.3333333333333333)) -> Val Loss: 0.12988848984241486\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 516ms/step - loss: 0.2883 - val_loss: 0.2695\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 511ms/step - loss: 0.2415 - val_loss: 0.2862\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 531ms/step - loss: 0.2348 - val_loss: 0.2711\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.2322 - val_loss: 0.2387\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.2319 - val_loss: 0.3408\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.2300 - val_loss: 0.2652\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 514ms/step - loss: 0.2299 - val_loss: 0.2248\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.2280 - val_loss: 0.2437\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.2280 - val_loss: 0.2597\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.2280 - val_loss: 0.2325\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.2279 - val_loss: 0.2144\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 515ms/step - loss: 0.2275 - val_loss: 0.2354\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.2261 - val_loss: 0.2352\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.2266 - val_loss: 0.2166\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.2273 - val_loss: 0.4118\n",
      "Epoch 16/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.2269 - val_loss: 0.2718\n",
      "Params (np.float64(0.2), np.float64(0.8)) -> Val Loss: 0.21440765261650085\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 520ms/step - loss: 0.2525 - val_loss: 0.2463\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 517ms/step - loss: 0.2021 - val_loss: 0.2466\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 528ms/step - loss: 0.1975 - val_loss: 0.2376\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.1936 - val_loss: 0.2272\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 531ms/step - loss: 0.1926 - val_loss: 0.2201\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.1912 - val_loss: 0.1876\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1902 - val_loss: 0.1834\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 520ms/step - loss: 0.1902 - val_loss: 0.1994\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1889 - val_loss: 0.2067\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1888 - val_loss: 0.1756\n",
      "Epoch 11/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1884 - val_loss: 0.1776\n",
      "Epoch 12/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 604ms/step - loss: 0.1883 - val_loss: 0.3444\n",
      "Epoch 13/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 431ms/step - loss: 0.1877 - val_loss: 0.1827\n",
      "Epoch 14/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1883 - val_loss: 0.2747\n",
      "Epoch 15/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 518ms/step - loss: 0.1877 - val_loss: 0.2057\n",
      "Params (np.float64(0.4), np.float64(0.6000000000000001)) -> Val Loss: 0.17559172213077545\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 517ms/step - loss: 0.1763 - val_loss: 0.2123\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 512ms/step - loss: 0.1315 - val_loss: 0.2142\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 527ms/step - loss: 0.1234 - val_loss: 0.2080\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.1194 - val_loss: 0.2038\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.1166 - val_loss: 0.2065\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 518ms/step - loss: 0.1143 - val_loss: 0.2579\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 519ms/step - loss: 0.1134 - val_loss: 0.3114\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 521ms/step - loss: 0.1125 - val_loss: 0.3783\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 516ms/step - loss: 0.1133 - val_loss: 0.3903\n",
      "Params (np.float64(0.8), np.float64(0.2)) -> Val Loss: 0.20377787947654724\n",
      "Epoch 1/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 522ms/step - loss: 0.2920 - val_loss: 0.2568\n",
      "Epoch 2/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 517ms/step - loss: 0.2463 - val_loss: 0.2592\n",
      "Epoch 3/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 532ms/step - loss: 0.2433 - val_loss: 0.2564\n",
      "Epoch 4/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 530ms/step - loss: 0.2406 - val_loss: 0.3020\n",
      "Epoch 5/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.2412 - val_loss: 0.2211\n",
      "Epoch 6/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 526ms/step - loss: 0.2385 - val_loss: 0.2336\n",
      "Epoch 7/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 517ms/step - loss: 0.2379 - val_loss: 0.2348\n",
      "Epoch 8/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 524ms/step - loss: 0.2361 - val_loss: 0.2319\n",
      "Epoch 9/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.2363 - val_loss: 0.2431\n",
      "Epoch 10/20\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 522ms/step - loss: 0.2357 - val_loss: 0.2299\n",
      "Params (np.float64(0.16666666666666669), np.float64(0.8333333333333334)) -> Val Loss: 0.22113719582557678\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(autoencoder, train_gen, val_gen, params, steps_per_epoch, val_steps):\n",
    "    y, z = [np.round(arr, 2) for arr in params]\n",
    "\n",
    "    loss_fn = CustomLoss(y=y, z=z)\n",
    "    model = clone_model(autoencoder)\n",
    "    model.compile(\n",
    "        loss=loss_fn,\n",
    "        optimizer=Adam(learning_rate=1e-3)\n",
    "    )\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    history=model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=20,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "        )\n",
    "\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "\n",
    "steps_per_epoch = int(len(train_paths) // BATCH_SIZE)\n",
    "steps_per_epoch_val = int(len(val_paths) // BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Evaluate Autoencoder for all the combinations of weights\n",
    "for params in param_combinations:\n",
    "    try:\n",
    "        val_loss = evaluate_model(autoencoder, train_dataset, validation_dataset, params, steps_per_epoch, steps_per_epoch_val)\n",
    "        print(f\"Params {params} -> Val Loss: {val_loss}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_params = params\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742674038240,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "Lw5YRfGkVH3h",
    "outputId": "1e6405db-0416-46f4-a460-e5e867036ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: (np.float64(0.8333333333333334), np.float64(0.16666666666666669)) -> Best Val Loss: 0.10360830277204514\n"
     ]
    }
   ],
   "source": [
    "# Resultados finales\n",
    "print(f\"Best Params: {best_params} -> Best Val Loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile y fit: Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CustomLoss(y=0.83, z=0.17)\n",
    "\n",
    "steps_per_epoch = int(len(train_paths) // BATCH_SIZE)\n",
    "steps_per_epoch_val = int(len(val_paths) // BATCH_SIZE)\n",
    "\n",
    "autoencoder.compile(\n",
    "    loss=loss_fn,\n",
    "    optimizer=Adam(learning_rate=1e-3)\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "autoencoder.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=steps_per_epoch_val,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(ENCODER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(autoencoder.history.history)\n",
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = validation_dataset.take(1)\n",
    "\n",
    "\n",
    "for images, _ in validation_images:\n",
    "    shuffled_images = tf.random.shuffle(images)\n",
    "    first_three_images = shuffled_images[:3]\n",
    "    break\n",
    "\n",
    "processed_images = []\n",
    "for img in first_three_images:\n",
    "    img_with_batch = tf.expand_dims(img, axis=0)\n",
    "    processed_image = autoencoder(img_with_batch).numpy()\n",
    "    processed_images.append(processed_image.squeeze())\n",
    "\n",
    "#Plot\n",
    "n = 0\n",
    "plt.figure(dpi=150)\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(first_three_images[n], cmap='gray')  # Mostrar la imagen original\n",
    "plt.axis(False)\n",
    "plt.title(f\"Original Image {n+1}\")\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.imshow(processed_images[n], cmap='gray')  # Mostrar la imagen procesada\n",
    "plt.axis(False)\n",
    "plt.title(f\"Processed Image {n+1}\")\n",
    "\n",
    "\n",
    "n = 1\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.imshow(first_three_images[n], cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.title(f\"Original Image {n+1}\")\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.imshow(processed_images[n], cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.title(f\"Processed Image {n+1}\")\n",
    "\n",
    "\n",
    "n = 2\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.imshow(first_three_images[n], cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.title(f\"Original Image {n+1}\")\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.imshow(processed_images[n], cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.title(f\"Processed Image {n+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [
    {
     "file_id": "17fh03dC7Xnj01xPDUBtuOTxF4UMVvLyU",
     "timestamp": 1734488237097
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
