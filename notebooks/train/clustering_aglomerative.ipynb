{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDHEDClzf-FX",
        "outputId": "b827874b-b110-49ed-faf3-35417df047de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-05 22:14:15.418998: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-05 22:14:15.426600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743902055.434527   61173 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743902055.436948   61173 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-05 22:14:15.445128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, InceptionV3, DenseNet121, MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import shutil\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuJrQK8lf-FZ"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_e2MDaxdf-Fa"
      },
      "outputs": [],
      "source": [
        "def get_relative_file_paths(folder_path):\n",
        "\n",
        "    \"\"\"\n",
        "    Gets a list of relative paths to all files within a given folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of relative file paths.\n",
        "    \"\"\"\n",
        "\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_paths.append(file_path)\n",
        "    return file_paths\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yif0wG_YoY1P"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5ZYiW1XTf-Fb"
      },
      "outputs": [],
      "source": [
        "#METHOD = 'kmeans'\n",
        "METHOD = 'agglomerative'\n",
        "# METHOD = 'hdbscan'\n",
        "\n",
        "NUM_CLUSTERS = 15 #5 # Elejido a mano\n",
        "\n",
        "MODEL = 'VGG16'\n",
        "\n",
        "INPUT_SHAPE = (128, 128, 3)\n",
        "IMAGE_DIR = \"../../output/cropped_cells_full_v4/media/\"\n",
        "ENCODER_PATH = \"/content/drive/My Drive/Investigacion/UTN/GIAR/Results/Autoencoder/encoder_SSIM_MAE_Bparams.keras\"\n",
        "output_path_dataset = f\"../../media/{MODEL}_{METHOD}_v0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxprH8hrf-Fb"
      },
      "source": [
        "#### Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VaLp-7Rf-Fb",
        "outputId": "ce18ff47-affa-41bb-e57b-a2567e8e320d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1743902057.486547   61173 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21612 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "if MODEL == \"AutoEncoder\":\n",
        "    encoder = keras.saving.load_model(ENCODER_PATH)\n",
        "else:\n",
        "    # Load pre-trained models\n",
        "    if MODEL == 'VGG16':\n",
        "        preprocess_input = keras.applications.vgg16.preprocess_input\n",
        "        encoder = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "    elif MODEL == 'VGG19':\n",
        "        preprocess_input = keras.applications.vgg19.preprocess_input\n",
        "        VGG19(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "    elif MODEL == 'ResNet50':\n",
        "        preprocess_input = tf.keras.layers.Identity\n",
        "        ResNet50(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "    elif MODEL == 'InceptionV3':\n",
        "        preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "        InceptionV3(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "    elif MODEL == 'DenseNet121':\n",
        "        preprocess_input = tf.keras.layers.Identity\n",
        "        DenseNet121(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "    elif MODEL == 'MobileNetV2':\n",
        "        preprocess_input = tf.keras.layers.Identity\n",
        "        MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
        "\n",
        "    inp = keras.Input(shape=INPUT_SHAPE)\n",
        "    x = preprocess_input(inp)\n",
        "    x = encoder(x)\n",
        "    x = Flatten()(x)\n",
        "    encoder = Model(inputs=inp, outputs=x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jZiTVXBZmXB",
        "outputId": "cdb4d66b-3e93-474e-ab5b-8d0db7ff0301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de archivos: 53633\n"
          ]
        }
      ],
      "source": [
        "file_count = len(os.listdir(IMAGE_DIR))\n",
        "print(f\"Total de archivos: {file_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAXOMxI1f-Fc",
        "outputId": "77f0f380-3023-4551-b095-a107cf3bd7e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 8192)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pwcic29Rf-Fd"
      },
      "outputs": [],
      "source": [
        "image_paths = sorted(get_relative_file_paths(IMAGE_DIR))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhRiygjdf-Fd"
      },
      "source": [
        "# Load the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NBGANLX_f-Fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nicolas/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from tqdm.contrib.concurrent import process_map\n",
        "\n",
        "def load_image (x):\n",
        "    if MODEL == \"AutoEncoder\":\n",
        "        return cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        return cv2.imread(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vMq7oqnYiPG",
        "outputId": "e3c30a9e-8ae2-4091-e9ef-88ef13b7b9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f0ff720b5c6f4a9783423fa184233a42",
            "2c7fdd7888fa4607b5023ce53dec35ca",
            "1c8b240626094a0b887c4d0a4adf5f7f",
            "9e9bbe7035cd41f0acff637e5b2301fe",
            "9ed19ef9ad8c42dd96a261bd49a41ea4",
            "3b7d00d7a84f43929737f361f6b993d8",
            "a97d09a032e84d4b8f2b87215e160076",
            "b6f33efc770d452c9a7792962f1acec9",
            "3d3bc87eb74a4d46aef6e171d9e6a177",
            "c1025c6e0fcb4b038cd67b9882434e69",
            "3f540623a1a14b4b9db31a00dd714d27"
          ]
        },
        "id": "T5JoJWiKf-Fe",
        "outputId": "b6106cdf-ad9e-480b-aad3-598d21477020"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53633/53633 [00:02<00:00, 23113.13it/s]\n"
          ]
        }
      ],
      "source": [
        "images = process_map(\n",
        "                load_image,\n",
        "                image_paths,\n",
        "                total=len(image_paths),\n",
        "                max_workers=12,\n",
        "                chunksize=32,\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEWHgy-Ff-Fe"
      },
      "source": [
        "## Use encoder embeddings as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lVbFUU5lf-Fe"
      },
      "outputs": [],
      "source": [
        "#Transform input images for encoder input\n",
        "resized_images = [cv2.resize(image, INPUT_SHAPE[0:2]) for image in images]\n",
        "resized_images = np.array(resized_images)\n",
        "\n",
        "# images = images/255 # Esto esta incluido en el modelo\n",
        "\n",
        "#resized_images = [np.expand_dims(image, axis=(0, -1)) for image in resized_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7kWfsqZf-Fe",
        "outputId": "9819da3a-7fd5-4b54-b346-77815369d57b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53633, 128, 128, 3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if MODEL == \"AutoEncoder\":\n",
        "    resized_images = resized_images / 255.0\n",
        "    resized_images = np.expand_dims(resized_images, axis=-1)\n",
        "resized_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSLpGbQPf-Fe",
        "outputId": "59b71fce-e1f4-44e7-f081-8c0eb8b807c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 8192)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "encoder.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4VCzEOwof-Ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1743902063.516548   61254 service.cc:148] XLA service 0x713e400179e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1743902063.516568   61254 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
            "2025-04-05 22:14:23.522065: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1743902063.549649   61254 cuda_dnn.cc:529] Loaded cuDNN version 90701\n",
            "I0000 00:00:1743902064.720261   61254 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Extract features from encoder\n",
        "\n",
        "\n",
        "enc_features_array = np.zeros((resized_images.shape[0], encoder.output_shape[-1]))\n",
        "\n",
        "batch_size = 256\n",
        "ini = 0\n",
        "while True:\n",
        "    start = ini*batch_size\n",
        "    end = start+batch_size\n",
        "\n",
        "    if start >= resized_images.shape[0]:\n",
        "        break\n",
        "\n",
        "    if end >= resized_images.shape[0]:\n",
        "        end = resized_images.shape[0]-1\n",
        "\n",
        "\n",
        "    this_batch = resized_images[start:end]\n",
        "\n",
        "    enc_features_array[start:end] = encoder.predict(this_batch, verbose=0)\n",
        "\n",
        "    ini += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "llcSDT7af-Ff"
      },
      "outputs": [],
      "source": [
        "if METHOD == 'kmeans':\n",
        "    kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42)\n",
        "    kmeans.fit(enc_features_array)\n",
        "\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    seleccted_class = -np.ones((len(enc_features_array)), dtype=int)\n",
        "    for idx, feature in enumerate(enc_features_array):\n",
        "        dist = 1e99\n",
        "        for cluster in range(NUM_CLUSTERS):\n",
        "            t_dist = np.linalg.norm(feature - centroids[cluster])\n",
        "            if dist > t_dist:\n",
        "                dist = t_dist\n",
        "                seleccted_class[idx] = cluster\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage before: 20129.27 MB\n",
            "Memory usage after: 15672.58 MB\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import psutil\n",
        "\n",
        "enc_features_array_norm = [a / (np.linalg.norm(a) + 1e-16) for a in enc_features_array]\n",
        "print(f\"Memory usage before: {psutil.virtual_memory().used / 1024**2:.2f} MB\")\n",
        "images = None\n",
        "resized_images = None\n",
        "enc_features_array = None\n",
        "del enc_features_array\n",
        "del images\n",
        "del resized_images\n",
        "gc.collect()\n",
        "print(f\"Memory usage after: {psutil.virtual_memory().used / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if METHOD == 'agglomerative':\n",
        "    from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "    # Aca si o si normalizamos\n",
        "    # enc_features_array_norm = [a / (np.linalg.norm(a) + 1e-16) for a in enc_features_array]\n",
        "\n",
        "    # ag_clustering = AgglomerativeClustering\n",
        "    #     n_clusters = None,\n",
        "    #     metric = 'euclidean',\n",
        "    #     linkage = 'ward',\n",
        "    #     distance_threshold = 1.0,\n",
        "    #     compute_full_tree = True,\n",
        "    # )\n",
        "\n",
        "    ag_clustering = AgglomerativeClustering(\n",
        "        n_clusters = NUM_CLUSTERS,\n",
        "        linkage = 'ward',\n",
        "    )\n",
        "\n",
        "    clustering = ag_clustering.fit(enc_features_array_norm)\n",
        "    # seleccted_class = clustering.labels_\n",
        "\n",
        "joblib.dump(clustering, '../../models/agglomerative_clustering.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8NqI1juf-Ff"
      },
      "outputs": [],
      "source": [
        "if METHOD == 'hdbscan':\n",
        "    from sklearn.cluster import HDBSCAN\n",
        "    hdb = HDBSCAN()\n",
        "    clustering = hdb.fit(enc_features_array_norm)\n",
        "    seleccted_class = clustering.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhAHT7n4f-Ff",
        "outputId": "08154375-5266-46b8-ee46-8946663301dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(seleccted_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVl7LAKOf-Fg"
      },
      "source": [
        "### Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rAwXQ-5f-Fg"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists('./output/noise'):\n",
        "#     os.makedirs('./output/noise')\n",
        "\n",
        "# if not os.path.exists('./output/cells'):\n",
        "#     os.makedirs('./output/cells')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsn2FA0Rf-Fg"
      },
      "source": [
        "#### Get cluster representatrives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSFooTnvf-Fg",
        "outputId": "3eccf59f-b0d3-432a-9c8b-622c34ee6dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 100\n",
            "1 100\n",
            "2 100\n",
            "3 100\n",
            "4 100\n",
            "5 100\n",
            "6 100\n",
            "7 100\n",
            "8 100\n",
            "9 100\n",
            "10 100\n",
            "11 100\n",
            "12 100\n",
            "13 100\n",
            "14 100\n"
          ]
        }
      ],
      "source": [
        "NUM_CLUSTERS = len(np.unique(seleccted_class))\n",
        "GRID_SIZE = 10\n",
        "NUM_SHOW = GRID_SIZE*GRID_SIZE\n",
        "\n",
        "rep_images =[[] for _ in range(NUM_CLUSTERS)]\n",
        "for cluster in range(NUM_CLUSTERS):\n",
        "    for idx, label in enumerate(seleccted_class):\n",
        "        if label >= 0:\n",
        "            if len(rep_images[label]) < NUM_SHOW:\n",
        "                rep_images[label].append(resized_images[idx])\n",
        "                # if label == 1:\n",
        "                #     print(idx, label)\n",
        "\n",
        "for rep_idx, rep_list in enumerate(rep_images):\n",
        "    print(rep_idx, len(rep_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY3IboW07hTb",
        "outputId": "2975fce0-75ba-4a7c-e2fa-1406c32d7439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(rep_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pZNWiMozf-Fg",
        "outputId": "9407494a-a37e-4f80-cfb7-a6a5ce476862"
      },
      "outputs": [],
      "source": [
        "\n",
        "for rep_idx, rep_list in enumerate(rep_images):\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    n = 1\n",
        "    for image in rep_list:\n",
        "        plt.subplot(GRID_SIZE,GRID_SIZE,n)\n",
        "        plt.imshow(image,cmap=\"gray\")\n",
        "        plt.axis(False)\n",
        "        n+=1\n",
        "    plt.suptitle(f\"Cluster {rep_idx}\", fontsize=20, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lnM1j1cf-Fg"
      },
      "source": [
        "#### Create noise/cell dataset from predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ghpx6Vvjf-Fg",
        "outputId": "e2bd08a9-bf8a-4759-e007-08007e3796f9"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Pick a cluster MANUALLY!!!!! (this is to catch \"run all\" executions)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e8425b80cc12>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pick a cluster MANUALLY!!!!! (this is to catch \\\"run all\\\" executions)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Pick a cluster MANUALLY!!!!! (this is to catch \"run all\" executions)"
          ]
        }
      ],
      "source": [
        "raise ValueError(\"Pick a cluster MANUALLY!!!!! (this is to catch \\\"run all\\\" executions)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQk4QcwLf-Fg"
      },
      "outputs": [],
      "source": [
        "# Manually pick one\n",
        "CELL_CLUSTERS = [8,11,12,13]\n",
        "#NOT_CLUSTERS=[1,4,6,8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfOrougAf-Fh",
        "outputId": "bb704895-0558-4698-d8a4-017534c372ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:\n",
            "004 92\n",
            "Entrega1 6\n",
            "005 9\n",
            "003 57\n",
            "002 50\n",
            "001 58\n",
            "Validation:\n",
            "004 40\n",
            "Entrega1 3\n",
            "005 4\n",
            "003 25\n",
            "002 22\n",
            "001 26\n"
          ]
        }
      ],
      "source": [
        "SPLIT = 0.7\n",
        "realization_samples = dict()\n",
        "for file in os.listdir(IMAGE_DIR):\n",
        "    base, realiz, _ = file.split(\"_\")\n",
        "    if base not in realization_samples.keys():\n",
        "        realization_samples[base]  = set()\n",
        "    realization_samples[base].add(realiz)\n",
        "\n",
        "\n",
        "train_samples = dict()\n",
        "validation_samples = dict()\n",
        "for key in realization_samples.keys():\n",
        "    images_here = len(realization_samples[key])\n",
        "\n",
        "    train_images_here = int(np.floor(images_here*SPLIT))\n",
        "    this_train_sample = np.random.choice(list(realization_samples[key]), train_images_here, replace=False)\n",
        "    if key not in train_samples.keys():\n",
        "        train_samples[key]  = list()\n",
        "        validation_samples[key]  = list()\n",
        "    train_samples[key] = this_train_sample\n",
        "    validation_samples[key] = [a for a in list(realization_samples[key]) if a not in this_train_sample]\n",
        "\n",
        "print(\"Train:\")\n",
        "for key in train_samples.keys():\n",
        "    print(key, len(train_samples[key]))\n",
        "print(\"Validation:\")\n",
        "for key in validation_samples.keys():\n",
        "    print(key, len(validation_samples[key]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os9qRq0tf-Fh"
      },
      "outputs": [],
      "source": [
        "max_class = 3500\n",
        "\n",
        "\n",
        "\n",
        "# Random Shuffle\n",
        "indices = np.arange(seleccted_class.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "seleccted_class_shuffle = seleccted_class[indices]\n",
        "image_paths_shuffle = np.array(image_paths)[indices]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if os.path.exists(output_path_dataset):\n",
        "    shutil.rmtree(output_path_dataset)\n",
        "os.makedirs(os.path.join(output_path_dataset, 'train', \"not\"))\n",
        "os.makedirs(os.path.join(output_path_dataset, 'train', \"cells\"))\n",
        "os.makedirs(os.path.join(output_path_dataset, 'validation', \"not\"))\n",
        "os.makedirs(os.path.join(output_path_dataset, 'validation', \"cells\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for idx, cluster in enumerate(seleccted_class_shuffle):\n",
        "    if cluster >= 0:\n",
        "        if cluster in CELL_CLUSTERS:\n",
        "            folder = \"cells\"\n",
        "        else:\n",
        "            folder = \"not\"\n",
        "\n",
        "        file = image_paths_shuffle[idx]\n",
        "        img_name = os.path.basename(file)\n",
        "        base, realiz, _ = img_name.split(\"_\")\n",
        "\n",
        "        if realiz in train_samples[base]:\n",
        "            split = \"train\"\n",
        "        else:\n",
        "            split = \"validation\"\n",
        "\n",
        "        if len(os.listdir(os.path.join(output_path_dataset, split,folder))) >= max_class:\n",
        "            continue\n",
        "\n",
        "\n",
        "        shutil.copyfile(file, os.path.join(output_path_dataset, split, folder, img_name))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lppb-rZVf-Fh",
        "outputId": "08366eea-cd22-44a7-9237-374f391615af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16_agglomerative_v0\n"
          ]
        }
      ],
      "source": [
        "print(os.path.basename(output_path_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbKzIccif-Fh",
        "outputId": "c6301e88-d3d7-48a9-f9bb-15ac571f4c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3500\n",
            "3500\n",
            "3500\n",
            "3193\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir(os.path.join(output_path_dataset, \"train\", \"not\"))))\n",
        "print(len(os.listdir(os.path.join(output_path_dataset, \"train\", \"cells\"))))\n",
        "print(len(os.listdir(os.path.join(output_path_dataset, \"validation\", \"not\"))))\n",
        "print(len(os.listdir(os.path.join(output_path_dataset, \"validation\", \"cells\"))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tavIF0rn9Rbb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c8b240626094a0b887c4d0a4adf5f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f33efc770d452c9a7792962f1acec9",
            "max": 51652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d3bc87eb74a4d46aef6e171d9e6a177",
            "value": 51652
          }
        },
        "2c7fdd7888fa4607b5023ce53dec35ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7d00d7a84f43929737f361f6b993d8",
            "placeholder": "​",
            "style": "IPY_MODEL_a97d09a032e84d4b8f2b87215e160076",
            "value": "100%"
          }
        },
        "3b7d00d7a84f43929737f361f6b993d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3bc87eb74a4d46aef6e171d9e6a177": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f540623a1a14b4b9db31a00dd714d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9bbe7035cd41f0acff637e5b2301fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1025c6e0fcb4b038cd67b9882434e69",
            "placeholder": "​",
            "style": "IPY_MODEL_3f540623a1a14b4b9db31a00dd714d27",
            "value": " 51652/51652 [56:50&lt;00:00, 13.78it/s]"
          }
        },
        "9ed19ef9ad8c42dd96a261bd49a41ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97d09a032e84d4b8f2b87215e160076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f33efc770d452c9a7792962f1acec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1025c6e0fcb4b038cd67b9882434e69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ff720b5c6f4a9783423fa184233a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c7fdd7888fa4607b5023ce53dec35ca",
              "IPY_MODEL_1c8b240626094a0b887c4d0a4adf5f7f",
              "IPY_MODEL_9e9bbe7035cd41f0acff637e5b2301fe"
            ],
            "layout": "IPY_MODEL_9ed19ef9ad8c42dd96a261bd49a41ea4"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
