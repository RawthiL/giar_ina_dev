{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links\n",
    "\n",
    "#### <u>Datasets</u>\n",
    "Complete dataset: The full dataset of images used can be found [here](https://drive.google.com/drive/folders/1Rz0JrjUCU-4VmDkolbkwUcM8xW1jd9pl?usp=drive_link)\n",
    "\n",
    "Cropped datasets: The complete dataset has been used by SAM to create segmentations of cells, with some noise, resulting in:\n",
    " All these [crops](https://drive.google.com/drive/folders/1Rz0JrjUCU-4VmDkolbkwUcM8xW1jd9pl?usp=drive_link) \n",
    " and all these [csv files](https://frbautneduar-my.sharepoint.com/:u:/g/personal/ntaurozzi_frba_utn_edu_ar/EYKi5F-wXGRNkAqjPSRVhvUByTsnsEB10OrZiJHclkOPWQ?e=tVwmkS) with the information of each crop.\n",
    "\n",
    "Input/Target dataset: From the complete dataset, some images have been tagged by the biologists an those 58 (for now) can be found [here](https://frbautneduar-my.sharepoint.com/:u:/g/personal/ntaurozzi_frba_utn_edu_ar/EQbvUOwADihJsJLAyVfBdYwBDvHJDMS5GQuyyP_PzUeCLQ?e=z8A7Tn) each image with its corresponding target. The name of the images here are ids given to them by a json file.\n",
    "\n",
    "#### <u>Auxiliary files</u>\n",
    "To create the input/target dataset from the complete dataset, this [json](https://drive.google.com/file/d/1ydQ2fIOllwPPU64Kneda4mVidUww1X9T/view?usp=drive_link) was used\n",
    "\n",
    "#### <u>Models</u>\n",
    "For making the predictions these [models](https://frbautneduar-my.sharepoint.com/:f:/g/personal/lmareque_frba_utn_edu_ar/EiDo8WYptOpEiyzJHhQIbwoBUAfsoULwRRKEm-fmgzQD-g?e=6TE9yu) will be used\n",
    "\n",
    "### Code walkthrough\n",
    "\n",
    "This notebook will process all the images from the input/target dataset. It will use the json file to map the IDs to their original filenames. Then, it will search for all the crops belonging to these images and use all the models to predict whether each crop is noise or a cell. After the prediction, it will store the results in the corresponding CSV file for each image.\n",
    "\n",
    "The output will be a folder for each model used. Within each folder, a CSV file will be created for each image, containing information about the bounding boxes of each crop and its classification (cell or noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Qh0_ITlO0ATe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 18:55:32.772897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734904532.854361   55042 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734904532.878342   55042 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-22 18:55:33.059501: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import math\n",
    "import keras\n",
    "import cv2 as cv\n",
    "import json\n",
    "sys.path.insert(0, \"../packages/python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '../output/sam_uploaded_out/'\n",
    "CROPS_PATH = '../output/cropped_cells_full/'\n",
    "MODELS_PATH = '../models/'\n",
    "IMAGES_PATH = '../media/data/input/'\n",
    "JSON_PATH = '../media/corte-28-10-2023.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cell(model_path, image_path, images_batch):\n",
    "  \"\"\"\n",
    "  Given an image batch it returns the predictions of the batch with the given model.\n",
    "\n",
    "  Args:\n",
    "    model_path: path to the keras model to use.\n",
    "    image_path: path to the folder where the images are.\n",
    "    images_batch: list of the image names to include in the batch\n",
    "\n",
    "  Returns:\n",
    "    A list of predictions.\n",
    "  \"\"\"\n",
    "  images = []\n",
    "  for image in images_batch:\n",
    "      img = cv.imread(image_path+image)#, cv.IMREAD_GRAYSCALE)\n",
    "      img = cv.resize(img, (128, 128))\n",
    "      img = img / 255.0 \n",
    "      images.append(img)\n",
    "\n",
    "  model = keras.models.load_model(model_path)\n",
    "  batch = np.stack(images)\n",
    "  prediction = model.predict(batch, verbose=0)\n",
    "\n",
    "  return prediction #True if prediction >= 0.5 else False\n",
    "\n",
    "\n",
    "def find_image_name(data, id):\n",
    "  \"\"\"\n",
    "  Given a list of objects it searches the file_name from the id.\n",
    "\n",
    "  Args:\n",
    "    data: list of objects to search from.\n",
    "    id: id of the file name to return.\n",
    "\n",
    "  Returns:\n",
    "    The file name of the image id.\n",
    "  \"\"\"\n",
    "  for img in data:\n",
    "      if img['id'] == id:\n",
    "          base_name, _ = os.path.splitext(img['file_name'])\n",
    "          return base_name\n",
    "        \n",
    "\n",
    "def process_images_in_batches(string_list, batch_size=10):\n",
    "  \"\"\"\n",
    "  Processes a list of strings in batches of a specified size.\n",
    "\n",
    "  Args:\n",
    "    string_list: The list of strings to process.\n",
    "    batch_size: The size of each batch.\n",
    "\n",
    "  Yields:\n",
    "    A batch of strings.\n",
    "  \"\"\"\n",
    "  for i in range(0, len(string_list), batch_size):\n",
    "    batch_num = i // batch_size + 1  # Calculate batch number (1-indexed)\n",
    "    yield batch_num, string_list[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of elements to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = sorted(os.listdir(CSV_PATH)) #Paths to the csv of SAM detections of each image\n",
    "crops = sorted(os.listdir(CROPS_PATH)) #Paths to the crops made from SAM detection of the full_images\n",
    "models = sorted(os.listdir(MODELS_PATH)) #Models to use in the prediction\n",
    "og_images = sorted(os.listdir(IMAGES_PATH)) #full_images from where the crops are made\n",
    "with open(JSON_PATH, 'r') as f: #json with the information of the filename of the images\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    \n",
    "    base_model, _ = os.path.splitext(model)\n",
    "    output = f\"../output/evaluated/{base_model}\"\n",
    "    if not os.path.exists(output): #Create dirs for each model used\n",
    "        os.makedirs(output)\n",
    "\n",
    "    for og_image_idx, og_image in enumerate(og_images):\n",
    "        img_name, _ = os.path.splitext(og_image)\n",
    "        real_name = find_image_name(data['images'], int(img_name)) #Find the real image name from where the crops where made\n",
    "        images = sorted([crop for crop in crops if crop.startswith(real_name)]) #Get all the crops from that image\n",
    "        df = pd.read_csv(os.path.join(CSV_PATH, f\"{real_name}.csv\")) #Read the csv of that image\n",
    "\n",
    "        batch_size=30\n",
    "        for idx, batch in process_images_in_batches(images, batch_size=batch_size): #Read the images in batch_size batches\n",
    "            print(f\"Model: {model} ({model_idx+1}/{len(models)}) - Image: {og_image} ({og_image_idx+1}/{len(og_images)}) - Batch {idx}/{math.ceil(len(images)/batch_size)}\", end='\\r')\n",
    "\n",
    "            batch_prediction = predict_cell(model_path=os.path.join(MODELS_PATH, model), image_path=CROPS_PATH, images_batch=batch)\n",
    "            is_cell = [True if sublist[0] >= 0.5 else False for sublist in batch_prediction]\n",
    "            # print(is_cell)\n",
    "\n",
    "            for idx, i in enumerate(batch):#For each batch store the prediction in the csv\n",
    "                crop_name, _ = os.path.splitext(i)\n",
    "                cell_id = crop_name.split('_')[2]\n",
    "\n",
    "                mask = (df['cell_id'] == int(cell_id)) & (df['image'] == real_name)\n",
    "                df.loc[mask, 'is_cell'] = is_cell[idx]\n",
    "                df.loc[mask, 'image'] = img_name \n",
    "        df.to_csv(os.path.join(output, f\"{img_name}.csv\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "IhGniA16bT4r"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
