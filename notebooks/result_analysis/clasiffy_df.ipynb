{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NM_bkf-K1Nm"
   },
   "source": [
    "## Classify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbLDGkpsK1Np"
   },
   "source": [
    "### Useful links\n",
    "\n",
    "#### <u>Datasets</u>\n",
    "Complete dataset: The full dataset of images used can be found [here](https://drive.google.com/drive/folders/1Rz0JrjUCU-4VmDkolbkwUcM8xW1jd9pl?usp=drive_link)\n",
    "\n",
    "Cropped datasets: The complete dataset has been used by SAM to create segmentations of cells, with some noise, resulting in:\n",
    " All these [crops](https://drive.google.com/drive/folders/1Rz0JrjUCU-4VmDkolbkwUcM8xW1jd9pl?usp=drive_link)\n",
    " and all these [csv files](https://frbautneduar-my.sharepoint.com/:u:/g/personal/ntaurozzi_frba_utn_edu_ar/EYKi5F-wXGRNkAqjPSRVhvUByTsnsEB10OrZiJHclkOPWQ?e=tVwmkS) with the information of each crop.\n",
    "\n",
    "Input/Target dataset: From the complete dataset, some images have been tagged by the biologists an those 58 (for now) can be found [here](https://frbautneduar-my.sharepoint.com/:u:/g/personal/ntaurozzi_frba_utn_edu_ar/EQbvUOwADihJsJLAyVfBdYwBDvHJDMS5GQuyyP_PzUeCLQ?e=z8A7Tn) each image with its corresponding target. The name of the images here are ids given to them by a json file.\n",
    "\n",
    "#### <u>Auxiliary files</u>\n",
    "To create the input/target dataset from the complete dataset, this [json](https://drive.google.com/file/d/1ydQ2fIOllwPPU64Kneda4mVidUww1X9T/view?usp=drive_link) was used\n",
    "\n",
    "#### <u>Models</u>\n",
    "For making the predictions these [models](https://frbautneduar-my.sharepoint.com/:f:/g/personal/lmareque_frba_utn_edu_ar/EiDo8WYptOpEiyzJHhQIbwoBUAfsoULwRRKEm-fmgzQD-g?e=6TE9yu) will be used\n",
    "\n",
    "### Code walkthrough\n",
    "\n",
    "This notebook will process all the images from the input/target dataset. It will use the json file to map the IDs to their original filenames. Then, it will search for all the crops belonging to these images and use all the models to predict whether each crop is noise or a cell. After the prediction, it will store the results in the corresponding CSV file for each image.\n",
    "\n",
    "The output will be a folder for each model used. Within each folder, a CSV file will be created for each image, containing information about the bounding boxes of each crop and its classification (cell or noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D9wKHvSK1Nr"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8444,
     "status": "ok",
     "timestamp": 1739547543305,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "Qh0_ITlO0ATe",
    "outputId": "60991a2c-7091-49de-db51-8e941131e3f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 22:10:58.537973: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 22:10:58.544310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746148258.551556  340879 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746148258.554003  340879 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746148258.559879  340879 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746148258.559886  340879 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746148258.559887  340879 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746148258.559888  340879 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-01 22:10:58.562093: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from shapely.geometry import Polygon\n",
    "from tensorflow.keras.applications import efficientnet_v2, convnext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAIP2PV8K1Nv"
   },
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739547543305,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "B0FEJeKWK1Nx"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../../\")\n",
    "from config import MEDIA_PATH, CROPPED_PATH, MODELS_PATH, RESULTS_PATH\n",
    "\n",
    "# Specific paths\n",
    "IMAGES_PATH = os.path.join(MEDIA_PATH, 'images', 'ina', 'images')\n",
    "CROPS_PATH = os.path.join(CROPPED_PATH, 'ina', 'images')\n",
    "CSV_PATH = os.path.join(CROPPED_PATH, 'ina', 'data')\n",
    "JSON_PATH = os.path.join(MEDIA_PATH, 'images', 'ina', 'tagged_images', 'corte-27-02-2024.json')\n",
    "MODELS_PATH = os.path.join(MODELS_PATH, 'supervised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EE4Qd1GyK1Nz"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739547543305,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "ll9lWzhHK1N0"
   },
   "outputs": [],
   "source": [
    "def predict_cell(model,model_name, image_path, images_batch, color_type):\n",
    "  \"\"\"\n",
    "  Given an image batch it returns the predictions of the batch with the given model.\n",
    "\n",
    "  Args:\n",
    "    model: keras model to use.\n",
    "    image_path: path to the folder where the images are.\n",
    "    images_batch: list of the image names to include in the batch\n",
    "\n",
    "  Returns:\n",
    "    A list of predictions.\n",
    "  \"\"\"\n",
    "\n",
    "  images = []\n",
    "  for image in images_batch:\n",
    "      img = cv.imread(os.path.join(image_path,image), color_type)\n",
    "\n",
    "      if model_name == 'model_EfficientNetB0.keras':\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, (224, 224))\n",
    "        img = efficientnet_v2.preprocess_input(img)\n",
    "        images.append(img)\n",
    "\n",
    "      elif model_name == \"model_ConvNeXtTiny.keras\":\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, (224, 224))\n",
    "        img = convnext.preprocess_input(img)\n",
    "        images.append(img)\n",
    "\n",
    "      else:\n",
    "        img = cv.resize(img, (128, 128))\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "\n",
    "\n",
    "  batch = np.stack(images)\n",
    "  if color_type == cv.IMREAD_GRAYSCALE:\\\n",
    "    # Add missing channel\n",
    "    batch = np.expand_dims(batch, axis=-1).astype(np.float32)\n",
    "\n",
    "  prediction = model.predict(batch, verbose=0)\n",
    "  prediction = tf.nn.softmax(prediction, axis=-1)\n",
    "  return prediction\n",
    "\n",
    "\n",
    "def find_image_name(data, id):\n",
    "  \"\"\"\n",
    "  Given a list of objects it searches the file_name from the id.\n",
    "\n",
    "  Args:\n",
    "    data: list of objects to search from.\n",
    "    id: id of the file name to return.\n",
    "\n",
    "  Returns:\n",
    "    The file name of the image id.\n",
    "  \"\"\"\n",
    "  for img in data:\n",
    "      if img['id'] == id:\n",
    "          base_name, _ = os.path.splitext(img['file_name'])\n",
    "          return base_name\n",
    "\n",
    "def get_cells_bbox(data, id):\n",
    "  \"\"\"\n",
    "  Given a list of objects it returns a list of bounding boxes for the given id.\n",
    "\n",
    "  Args:\n",
    "    data: list of objects to search from.\n",
    "    id: id of the objetct to search.\n",
    "\n",
    "  Returns:\n",
    "    A list of bounding boxes.\n",
    "  \"\"\"\n",
    "  return [cell['bbox'] for cell in data['annotations'] if cell['image_id'] == id]\n",
    "\n",
    "def process_images_in_batches(string_list, batch_size=10):\n",
    "  \"\"\"\n",
    "  Processes a list of strings in batches of a specified size.\n",
    "\n",
    "  Args:\n",
    "    string_list: The list of strings to process.\n",
    "    batch_size: The size of each batch.\n",
    "\n",
    "  Yields:\n",
    "    A batch of strings.\n",
    "  \"\"\"\n",
    "  for i in range(0, len(string_list), batch_size):\n",
    "    batch_num = i // batch_size + 1  # Calculate batch number (1-indexed)\n",
    "    yield batch_num, string_list[i:i + batch_size]\n",
    "\n",
    "def bb_overlap_percentage(box1, box2):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) of two bounding boxes using Shapely.\n",
    "\n",
    "    Args:\n",
    "        box1: A tuple or list containing (x1, y1, width, height) of the first bounding box.\n",
    "        box2: A tuple or list containing (x1, y1, width, height) of the second bounding box.\n",
    "\n",
    "    Returns:\n",
    "        The IoU value, a float between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate box coordinates\n",
    "    x1_min, y1_min, width1, height1 = box1\n",
    "    x1_max = x1_min + width1\n",
    "    y1_max = y1_min + height1\n",
    "    x2_min, y2_min, width2, height2 = box2\n",
    "    x2_max = x2_min + width2\n",
    "    y2_max = y2_min + height2\n",
    "\n",
    "    # Create polygons\n",
    "    poly1 = Polygon([(x1_min, y1_min), (x1_max, y1_min), (x1_max, y1_max), (x1_min, y1_max)])\n",
    "    poly2 = Polygon([(x2_min, y2_min), (x2_max, y2_min), (x2_max, y2_max), (x2_min, y2_max)])\n",
    "\n",
    "    # Calculate intersection and union areas\n",
    "    intersection = poly1.intersection(poly2).area\n",
    "    union = poly1.union(poly2).area\n",
    "\n",
    "    #print(poly1.area, poly2.area, intersection)\n",
    "\n",
    "    return intersection / poly1.area if union > 0 else 0.0\n",
    "\n",
    "def bbox_fully_contained(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Checks if bounding box 1 is fully contained within bounding box 2.\n",
    "\n",
    "    Args:\n",
    "        bbox1: A tuple (x1, y1, width1, height1) representing the first bounding box.\n",
    "        bbox2: A tuple (x2, y2, width2, height2) representing the second bounding box.\n",
    "\n",
    "    Returns:\n",
    "        True if bbox1 is fully contained within bbox2, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate coordinates of bounding boxes\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "    bbox1_coords = [(x1, y1), (x1 + w1, y1), (x1 + w1, y1 + h1), (x1, y1 + h1)]\n",
    "    bbox2_coords = [(x2, y2), (x2 + w2, y2), (x2 + w2, y2 + h2), (x2, y2 + h2)]\n",
    "\n",
    "    # Create Shapely polygons\n",
    "    poly1 = Polygon(bbox1_coords)\n",
    "    poly2 = Polygon(bbox2_coords)\n",
    "\n",
    "    # Check if bbox1 is fully contained within bbox2\n",
    "    return poly1.within(poly2)\n",
    "\n",
    "def bbox_intercept(bbox, bbox_list, threshold=0):\n",
    "  for idx, bbox_target in enumerate(bbox_list):\n",
    "    if threshold > 0: # 0.75\n",
    "      iou = bb_overlap_percentage(bbox, bbox_target)\n",
    "      if iou >= threshold:\n",
    "        return True, idx\n",
    "\n",
    "    else:\n",
    "      contained = bbox_fully_contained(bbox, bbox_target)\n",
    "      if contained:\n",
    "        return True, idx\n",
    "\n",
    "  return False, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJrUWrmRK1N1"
   },
   "source": [
    "### Lists of elements to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1739547544811,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "2_N4rhrPK1N3"
   },
   "outputs": [],
   "source": [
    "csvs = sorted(os.listdir(CSV_PATH)) #Paths to the csv of SAM detections of each image\n",
    "crops = sorted(os.listdir(CROPS_PATH)) #Paths to the crops made from SAM detection of the full_images\n",
    "models = sorted(os.listdir(MODELS_PATH)) #Models to use in the prediction\n",
    "og_images = sorted(os.listdir(IMAGES_PATH)) #full_images from where the crops are made\n",
    "with open(JSON_PATH, 'r') as f: #json with the information of the filename of the images\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPig-pjZK1N4"
   },
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5u0zY-ffK1N4",
    "outputId": "82ab7cbd-7d44-4e4c-a9fb-cd1609b516e0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model model_Encoder_SSIM+MAE0 (1)\n",
      "skipping 001_00001.jpg (None), no tags.\n",
      "skipping 001_00002.jpg (None), no tags.\n",
      "skipping 001_00003.jpg (None), no tags.\n",
      "skipping 001_00004.jpg (None), no tags.\n",
      "skipping 001_00005.jpg (None), no tags.\n",
      "skipping 001_00006.jpg (None), no tags.\n",
      "skipping 001_00007.jpg (None), no tags.\n",
      "skipping 001_00008.jpg (None), no tags.\n",
      "skipping 001_00009.jpg (None), no tags.\n",
      "skipping 001_00010.jpg (None), no tags.\n",
      "skipping 001_00011.jpg (None), no tags.\n",
      "skipping 001_00012.jpg (None), no tags.\n",
      "skipping 001_00013.jpg (None), no tags.\n",
      "skipping 001_00014.jpg (None), no tags.\n",
      "skipping 001_00015.jpg (None), no tags.\n",
      "skipping 001_00016.jpg (None), no tags.\n",
      "skipping 001_00017.jpg (None), no tags.\n",
      "skipping 001_00018.jpg (None), no tags.\n",
      "skipping 001_00019.jpg (None), no tags.\n",
      "skipping 001_00020.jpg (None), no tags.\n",
      "skipping 001_00021.jpg (None), no tags.\n",
      "skipping 001_00022.jpg (None), no tags.\n",
      "skipping 001_00023.jpg (None), no tags.\n",
      "skipping 001_00024.jpg (None), no tags.\n",
      "skipping 001_00025.jpg (None), no tags.\n",
      "skipping 001_00026.jpg (None), no tags.\n",
      "skipping 001_00027.jpg (None), no tags.\n",
      "skipping 001_00028.jpg (None), no tags.\n",
      "skipping 001_00029.jpg (None), no tags.\n",
      "skipping 001_00030.jpg (None), no tags.\n",
      "skipping 001_00031.jpg (None), no tags.\n",
      "skipping 001_00032.jpg (None), no tags.\n",
      "skipping 001_00033.jpg (None), no tags.\n",
      "skipping 001_00034.jpg (None), no tags.\n",
      "skipping 001_00035.jpg (None), no tags.\n",
      "skipping 001_00036.jpg (None), no tags.\n",
      "skipping 001_00037.jpg (None), no tags.\n",
      "skipping 001_00038.jpg (None), no tags.\n",
      "skipping 001_00039.jpg (None), no tags.\n",
      "skipping 001_00040.jpg (None), no tags.\n",
      "skipping 001_00041.jpg (None), no tags.\n",
      "skipping 001_00042.jpg (None), no tags.\n",
      "skipping 001_00043.jpg (None), no tags.\n",
      "skipping 001_00044.jpg (None), no tags.\n",
      "skipping 001_00045.jpg (None), no tags.\n",
      "skipping 001_00046.jpg (None), no tags.\n",
      "skipping 001_00047.jpg (None), no tags.\n",
      "skipping 001_00048.jpg (None), no tags.\n",
      "skipping 001_00049.jpg (None), no tags.\n",
      "skipping 001_00050.jpg (None), no tags.\n",
      "skipping 001_00051.jpg (None), no tags.\n",
      "skipping 001_00052.jpg (None), no tags.\n",
      "skipping 001_00053.jpg (None), no tags.\n",
      "skipping 001_00054.jpg (None), no tags.\n",
      "skipping 001_00055.jpg (None), no tags.\n",
      "skipping 001_00056.jpg (None), no tags.\n",
      "skipping 001_00057.jpg (None), no tags.\n",
      "skipping 001_00058.jpg (None), no tags.\n",
      "skipping 001_00059.jpg (None), no tags.\n",
      "skipping 001_00060.jpg (None), no tags.\n",
      "skipping 001_00061.jpg (None), no tags.\n",
      "skipping 001_00062.jpg (None), no tags.\n",
      "skipping 001_00063.jpg (None), no tags.\n",
      "skipping 001_00064.jpg (None), no tags.\n",
      "skipping 001_00065.jpg (None), no tags.\n",
      "skipping 001_00066.jpg (None), no tags.\n",
      "skipping 001_00067.jpg (None), no tags.\n",
      "skipping 001_00068.jpg (None), no tags.\n",
      "skipping 001_00069.jpg (None), no tags.\n",
      "skipping 001_00070.jpg (None), no tags.\n",
      "skipping 001_00071.jpg (None), no tags.\n",
      "skipping 001_00072.jpg (None), no tags.\n",
      "skipping 001_00073.jpg (None), no tags.\n",
      "skipping 001_00074.jpg (None), no tags.\n",
      "skipping 001_00075.jpg (None), no tags.\n",
      "skipping 001_00076.jpg (None), no tags.\n",
      "skipping 001_00077.jpg (None), no tags.\n",
      "skipping 001_00078.jpg (None), no tags.\n",
      "skipping 001_00079.jpg (None), no tags.\n",
      "skipping 001_00080.jpg (None), no tags.\n",
      "skipping 001_00081.jpg (None), no tags.\n",
      "skipping 001_00082.jpg (None), no tags.\n",
      "skipping 001_00083.jpg (None), no tags.\n",
      "skipping 001_00084.jpg (None), no tags.\n",
      "skipping 002_00001.jpg (None), no tags.\n",
      "skipping 002_00002.jpg (None), no tags.\n",
      "skipping 002_00003.jpg (None), no tags.\n",
      "skipping 002_00004.jpg (None), no tags.\n",
      "skipping 002_00005.jpg (None), no tags.\n",
      "skipping 002_00006.jpg (None), no tags.\n",
      "skipping 002_00007.jpg (None), no tags.\n",
      "skipping 002_00008.jpg (None), no tags.\n",
      "skipping 002_00009.jpg (None), no tags.\n",
      "skipping 002_00010.jpg (None), no tags.\n",
      "skipping 002_00011.jpg (None), no tags.\n",
      "skipping 002_00012.jpg (None), no tags.\n",
      "skipping 002_00013.jpg (None), no tags.\n",
      "skipping 002_00014.jpg (None), no tags.\n",
      "skipping 002_00015.jpg (None), no tags.\n",
      "skipping 002_00016.jpg (None), no tags.\n",
      "skipping 002_00017.jpg (None), no tags.\n",
      "skipping 002_00018.jpg (None), no tags.\n",
      "skipping 002_00019.jpg (None), no tags.\n",
      "skipping 002_00020.jpg (None), no tags.\n",
      "skipping 002_00021.jpg (None), no tags.\n",
      "skipping 002_00022.jpg (None), no tags.\n",
      "skipping 002_00023.jpg (None), no tags.\n",
      "skipping 002_00024.jpg (None), no tags.\n",
      "skipping 002_00025.jpg (None), no tags.\n",
      "skipping 002_00026.jpg (None), no tags.\n",
      "skipping 002_00027.jpg (None), no tags.\n",
      "skipping 002_00028.jpg (None), no tags.\n",
      "skipping 002_00029.jpg (None), no tags.\n",
      "skipping 002_00030.jpg (None), no tags.\n",
      "skipping 002_00031.jpg (None), no tags.\n",
      "skipping 002_00032.jpg (None), no tags.\n",
      "skipping 002_00033.jpg (None), no tags.\n",
      "skipping 002_00034.jpg (None), no tags.\n",
      "skipping 002_00035.jpg (None), no tags.\n",
      "skipping 002_00036.jpg (None), no tags.\n",
      "skipping 002_00037.jpg (None), no tags.\n",
      "skipping 002_00038.jpg (None), no tags.\n",
      "skipping 002_00039.jpg (None), no tags.\n",
      "skipping 002_00040.jpg (None), no tags.\n",
      "skipping 002_00041.jpg (None), no tags.\n",
      "skipping 002_00042.jpg (None), no tags.\n",
      "skipping 002_00043.jpg (None), no tags.\n",
      "skipping 002_00044.jpg (None), no tags.\n",
      "skipping 002_00045.jpg (None), no tags.\n",
      "skipping 002_00046.jpg (None), no tags.\n",
      "skipping 002_00047.jpg (None), no tags.\n",
      "skipping 002_00048.jpg (None), no tags.\n",
      "skipping 002_00049.jpg (None), no tags.\n",
      "skipping 002_00050.jpg (None), no tags.\n",
      "skipping 002_00051.jpg (None), no tags.\n",
      "skipping 002_00052.jpg (None), no tags.\n",
      "skipping 002_00053.jpg (None), no tags.\n",
      "skipping 002_00054.jpg (None), no tags.\n",
      "skipping 002_00055.jpg (None), no tags.\n",
      "skipping 002_00056.jpg (None), no tags.\n",
      "skipping 002_00057.jpg (None), no tags.\n",
      "skipping 002_00058.jpg (None), no tags.\n",
      "skipping 002_00059.jpg (None), no tags.\n",
      "skipping 002_00060.jpg (None), no tags.\n",
      "skipping 002_00061.jpg (None), no tags.\n",
      "skipping 002_00062.jpg (None), no tags.\n",
      "skipping 002_00063.jpg (None), no tags.\n",
      "skipping 002_00064.jpg (None), no tags.\n",
      "skipping 002_00065.jpg (None), no tags.\n",
      "skipping 002_00066.jpg (None), no tags.\n",
      "skipping 002_00067.jpg (None), no tags.\n",
      "skipping 002_00068.jpg (None), no tags.\n",
      "skipping 002_00069.jpg (None), no tags.\n",
      "skipping 002_00070.jpg (None), no tags.\n",
      "skipping 002_00071.jpg (None), no tags.\n",
      "skipping 002_00072.jpg (None), no tags.\n",
      "skipping 003_00001.jpg (None), no tags.\n",
      "skipping 003_00002.jpg (None), no tags.\n",
      "skipping 003_00003.jpg (None), no tags.\n",
      "skipping 003_00004.jpg (None), no tags.\n",
      "skipping 003_00005.jpg (None), no tags.\n",
      "skipping 003_00006.jpg (None), no tags.\n",
      "skipping 003_00007.jpg (None), no tags.\n",
      "skipping 003_00008.jpg (None), no tags.\n",
      "skipping 003_00009.jpg (None), no tags.\n",
      "skipping 003_00010.jpg (None), no tags.\n",
      "skipping 003_00011.jpg (None), no tags.\n",
      "skipping 003_00012.jpg (None), no tags.\n",
      "skipping 003_00013.jpg (None), no tags.\n",
      "skipping 003_00014.jpg (None), no tags.\n",
      "skipping 003_00015.jpg (None), no tags.\n",
      "skipping 003_00016.jpg (None), no tags.\n",
      "skipping 003_00017.jpg (None), no tags.\n",
      "skipping 003_00018.jpg (None), no tags.\n",
      "skipping 003_00019.jpg (None), no tags.\n",
      "skipping 003_00020.jpg (None), no tags.\n",
      "skipping 003_00021.jpg (None), no tags.\n",
      "skipping 003_00022.jpg (None), no tags.\n",
      "skipping 003_00023.jpg (None), no tags.\n",
      "skipping 003_00024.jpg (None), no tags.\n",
      "skipping 003_00025.jpg (None), no tags.\n",
      "skipping 003_00026.jpg (None), no tags.\n",
      "skipping 003_00027.jpg (None), no tags.\n",
      "skipping 003_00028.jpg (None), no tags.\n",
      "skipping 003_00029.jpg (None), no tags.\n",
      "skipping 003_00030.jpg (None), no tags.\n",
      "skipping 003_00031.jpg (None), no tags.\n",
      "skipping 003_00032.jpg (None), no tags.\n",
      "skipping 003_00033.jpg (None), no tags.\n",
      "skipping 003_00034.jpg (None), no tags.\n",
      "skipping 003_00035.jpg (None), no tags.\n",
      "skipping 003_00036.jpg (None), no tags.\n",
      "skipping 003_00037.jpg (None), no tags.\n",
      "skipping 003_00038.jpg (None), no tags.\n",
      "skipping 003_00039.jpg (None), no tags.\n",
      "skipping 003_00040.jpg (None), no tags.\n",
      "skipping 003_00041.jpg (None), no tags.\n",
      "skipping 003_00042.jpg (None), no tags.\n",
      "skipping 003_00043.jpg (None), no tags.\n",
      "skipping 003_00044.jpg (None), no tags.\n",
      "skipping 003_00045.jpg (None), no tags.\n",
      "skipping 003_00046.jpg (None), no tags.\n",
      "skipping 003_00047.jpg (None), no tags.\n",
      "skipping 003_00048.jpg (None), no tags.\n",
      "skipping 003_00049.jpg (None), no tags.\n",
      "skipping 003_00050.jpg (None), no tags.\n",
      "skipping 003_00051.jpg (None), no tags.\n",
      "skipping 003_00052.jpg (None), no tags.\n",
      "skipping 003_00053.jpg (None), no tags.\n",
      "skipping 003_00054.jpg (None), no tags.\n",
      "skipping 003_00055.jpg (None), no tags.\n",
      "skipping 003_00056.jpg (None), no tags.\n",
      "skipping 003_00057.jpg (None), no tags.\n",
      "skipping 003_00058.jpg (None), no tags.\n",
      "skipping 003_00059.jpg (None), no tags.\n",
      "skipping 003_00060.jpg (None), no tags.\n",
      "skipping 003_00061.jpg (None), no tags.\n",
      "skipping 003_00062.jpg (None), no tags.\n",
      "skipping 003_00063.jpg (None), no tags.\n",
      "skipping 003_00064.jpg (None), no tags.\n",
      "skipping 003_00065.jpg (None), no tags.\n",
      "skipping 003_00066.jpg (None), no tags.\n",
      "skipping 003_00067.jpg (None), no tags.\n",
      "skipping 003_00068.jpg (None), no tags.\n",
      "skipping 003_00069.jpg (None), no tags.\n",
      "skipping 003_00070.jpg (None), no tags.\n",
      "skipping 003_00071.jpg (None), no tags.\n",
      "skipping 003_00072.jpg (None), no tags.\n",
      "skipping 003_00073.jpg (None), no tags.\n",
      "skipping 003_00074.jpg (None), no tags.\n",
      "skipping 003_00075.jpg (None), no tags.\n",
      "skipping 003_00076.jpg (None), no tags.\n",
      "skipping 003_00077.jpg (None), no tags.\n",
      "skipping 003_00078.jpg (None), no tags.\n",
      "skipping 003_00079.jpg (None), no tags.\n",
      "skipping 003_00080.jpg (None), no tags.\n",
      "skipping 003_00081.jpg (None), no tags.\n",
      "skipping 003_00082.jpg (None), no tags.\n",
      "skipping 004_00001.jpg (None), no tags.\n",
      "skipping 004_00003.jpg (None), no tags.\n",
      "skipping 004_00004.jpg (None), no tags.\n",
      "skipping 004_00005.jpg (None), no tags.\n",
      "skipping 004_00006.jpg (None), no tags.\n",
      "skipping 004_00007.jpg (None), no tags.\n",
      "skipping 004_00008.jpg (None), no tags.\n",
      "skipping 004_00009.jpg (None), no tags.\n",
      "skipping 004_00010.jpg (None), no tags.\n",
      "skipping 004_00011.jpg (None), no tags.\n",
      "skipping 004_00012.jpg (None), no tags.\n",
      "skipping 004_00013.jpg (None), no tags.\n",
      "skipping 004_00014.jpg (None), no tags.\n",
      "skipping 004_00015.jpg (None), no tags.\n",
      "skipping 004_00016.jpg (None), no tags.\n",
      "skipping 004_00017.jpg (None), no tags.\n",
      "skipping 004_00018.jpg (None), no tags.\n",
      "skipping 004_00019.jpg (None), no tags.\n",
      "skipping 004_00020.jpg (None), no tags.\n",
      "skipping 004_00021.jpg (None), no tags.\n",
      "skipping 004_00022.jpg (None), no tags.\n",
      "skipping 004_00023.jpg (None), no tags.\n",
      "skipping 004_00024.jpg (None), no tags.\n",
      "skipping 004_00025.jpg (None), no tags.\n",
      "skipping 004_00026.jpg (None), no tags.\n",
      "skipping 004_00027.jpg (None), no tags.\n",
      "skipping 004_00028.jpg (None), no tags.\n",
      "skipping 004_00029.jpg (None), no tags.\n",
      "skipping 004_00030.jpg (None), no tags.\n",
      "skipping 004_00031.jpg (None), no tags.\n",
      "skipping 004_00032.jpg (None), no tags.\n",
      "skipping 004_00033.jpg (None), no tags.\n",
      "skipping 004_00034.jpg (None), no tags.\n",
      "skipping 004_00035.jpg (None), no tags.\n",
      "skipping 004_00036.jpg (None), no tags.\n",
      "skipping 004_00037.jpg (None), no tags.\n",
      "skipping 004_00038.jpg (None), no tags.\n",
      "skipping 004_00039.jpg (None), no tags.\n",
      "skipping 004_00040.jpg (None), no tags.\n",
      "skipping 004_00041.jpg (None), no tags.\n",
      "skipping 004_00042.jpg (None), no tags.\n",
      "skipping 004_00043.jpg (None), no tags.\n",
      "skipping 004_00044.jpg (None), no tags.\n",
      "skipping 004_00045.jpg (None), no tags.\n",
      "skipping 004_00046.jpg (None), no tags.\n",
      "skipping 004_00047.jpg (None), no tags.\n",
      "skipping 004_00048.jpg (None), no tags.\n",
      "skipping 004_00049.jpg (None), no tags.\n",
      "skipping 004_00050.jpg (None), no tags.\n",
      "skipping 004_00051.jpg (None), no tags.\n",
      "skipping 004_00052.jpg (None), no tags.\n",
      "skipping 004_00053.jpg (None), no tags.\n",
      "skipping 004_00054.jpg (None), no tags.\n",
      "skipping 004_00055.jpg (None), no tags.\n",
      "skipping 004_00056.jpg (None), no tags.\n",
      "skipping 004_00057.jpg (None), no tags.\n",
      "skipping 004_00058.jpg (None), no tags.\n",
      "skipping 004_00059.jpg (None), no tags.\n",
      "skipping 004_00060.jpg (None), no tags.\n",
      "skipping 004_00061.jpg (None), no tags.\n",
      "skipping 004_00062.jpg (None), no tags.\n",
      "skipping 004_00063.jpg (None), no tags.\n",
      "skipping 004_00064.jpg (None), no tags.\n",
      "skipping 004_00065.jpg (None), no tags.\n",
      "skipping 004_00066.jpg (None), no tags.\n",
      "skipping 004_00067.jpg (None), no tags.\n",
      "skipping 004_00068.jpg (None), no tags.\n",
      "skipping 004_00069.jpg (None), no tags.\n",
      "skipping 004_00070.jpg (None), no tags.\n",
      "skipping 004_00071.jpg (None), no tags.\n",
      "skipping 004_00072.jpg (None), no tags.\n",
      "skipping 004_00073.jpg (None), no tags.\n",
      "skipping 004_00074.jpg (None), no tags.\n",
      "skipping 004_00075.jpg (None), no tags.\n",
      "skipping 004_00076.jpg (None), no tags.\n",
      "skipping 004_00077.jpg (None), no tags.\n",
      "skipping 004_00078.jpg (None), no tags.\n",
      "skipping 004_00079.jpg (None), no tags.\n",
      "skipping 004_00080.jpg (None), no tags.\n",
      "skipping 004_00081.jpg (None), no tags.\n",
      "skipping 004_00082.jpg (None), no tags.\n",
      "skipping 004_00083.jpg (None), no tags.\n",
      "skipping 004_00084.jpg (None), no tags.\n",
      "skipping 004_00085.jpg (None), no tags.\n",
      "skipping 004_00086.jpg (None), no tags.\n",
      "skipping 004_00087.jpg (None), no tags.\n",
      "skipping 004_00088.jpg (None), no tags.\n",
      "skipping 004_00089.jpg (None), no tags.\n",
      "skipping 004_00090.jpg (None), no tags.\n",
      "skipping 004_00091.jpg (None), no tags.\n",
      "skipping 004_00092.jpg (None), no tags.\n",
      "skipping 004_00093.jpg (None), no tags.\n",
      "skipping 004_00094.jpg (None), no tags.\n",
      "skipping 004_00095.jpg (None), no tags.\n",
      "skipping 004_00096.jpg (None), no tags.\n",
      "skipping 004_00097.jpg (None), no tags.\n",
      "skipping 004_00098.jpg (None), no tags.\n",
      "skipping 004_00099.jpg (None), no tags.\n",
      "skipping 004_00100.jpg (None), no tags.\n",
      "skipping 004_00101.jpg (None), no tags.\n",
      "skipping 004_00102.jpg (None), no tags.\n",
      "skipping 004_00103.jpg (None), no tags.\n",
      "skipping 004_00104.jpg (None), no tags.\n",
      "skipping 004_00105.jpg (None), no tags.\n",
      "skipping 004_00106.jpg (None), no tags.\n",
      "skipping 004_00107.jpg (None), no tags.\n",
      "skipping 004_00108.jpg (None), no tags.\n",
      "skipping 004_00109.jpg (None), no tags.\n",
      "skipping 004_00110.jpg (None), no tags.\n",
      "skipping 004_00111.jpg (None), no tags.\n",
      "skipping 004_00112.jpg (None), no tags.\n",
      "skipping 004_00113.jpg (None), no tags.\n",
      "skipping 004_00114.jpg (None), no tags.\n",
      "skipping 004_00115.jpg (None), no tags.\n",
      "skipping 004_00116.jpg (None), no tags.\n",
      "skipping 004_00117.jpg (None), no tags.\n",
      "skipping 004_00118.jpg (None), no tags.\n",
      "skipping 004_00119.jpg (None), no tags.\n",
      "skipping 004_00120.jpg (None), no tags.\n",
      "skipping 004_00121.jpg (None), no tags.\n",
      "skipping 004_00122.jpg (None), no tags.\n",
      "skipping 004_00123.jpg (None), no tags.\n",
      "skipping 004_00124.jpg (None), no tags.\n",
      "skipping 004_00125.jpg (None), no tags.\n",
      "skipping 004_00126.jpg (None), no tags.\n",
      "skipping 004_00127.jpg (None), no tags.\n",
      "skipping 004_00128.jpg (None), no tags.\n",
      "skipping 004_00129.jpg (None), no tags.\n",
      "skipping 004_00130.jpg (None), no tags.\n",
      "skipping 004_00131.jpg (None), no tags.\n",
      "skipping 004_00132.jpg (None), no tags.\n",
      "skipping 004_00133.jpg (None), no tags.\n",
      "skipping 005_00001.jpg (None), no tags.\n",
      "skipping 005_00002.jpg (None), no tags.\n",
      "skipping 005_00010.jpg (None), no tags.\n",
      "skipping 005_00011.jpg (None), no tags.\n",
      "skipping 005_00012.jpg (None), no tags.\n",
      "skipping 005_00013.jpg (None), no tags.\n",
      "skipping 005_00014.jpg (None), no tags.\n",
      "skipping 005_00015.jpg (None), no tags.\n",
      "skipping 005_00016.jpg (None), no tags.\n",
      "skipping 005_00017.jpg (None), no tags.\n",
      "skipping 005_00018.jpg (None), no tags.\n",
      "skipping 005_00019.jpg (None), no tags.\n",
      "skipping 005_00020.jpg (None), no tags.\n",
      "skipping Entrega1_00004.jpg (None), no tags.\n",
      "skipping Entrega1_00006.jpg (None), no tags.\n",
      "skipping Entrega1_00007.jpg (None), no tags.\n",
      "skipping Entrega1_00008.jpg (None), no tags.\n",
      "skipping Entrega1_00009.jpg (None), no tags.\n",
      "skipping Entrega1_00010.jpg (None), no tags.\n",
      "skipping Entrega1_00011.jpg (None), no tags.\n",
      "skipping Entrega1_00012.jpg (None), no tags.\n",
      "skipping Entrega1_00017.jpg (None), no tags.\n",
      "DONE\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "first_pass = True\n",
    "for model_idx, model in enumerate(models):\n",
    "\n",
    "\n",
    "    base_model, ext = os.path.splitext(model)\n",
    "    if '.keras' != ext:\n",
    "        continue\n",
    "    print(f'Testing model {base_model.split(\".\")[0]}')\n",
    "\n",
    "    model_path=os.path.join(MODELS_PATH, model)\n",
    "    loaded_model = keras.models.load_model(model_path)\n",
    "\n",
    "    if loaded_model.input.shape[-1] == 1:\n",
    "        color_type = cv.IMREAD_GRAYSCALE\n",
    "    else:\n",
    "        color_type = cv.IMREAD_COLOR\n",
    "\n",
    "\n",
    "    output = os.path.join(RESULTS_PATH, \"evaluated\", base_model)\n",
    "\n",
    "    if not os.path.exists(output): #Create dirs for each model used\n",
    "        os.makedirs(output)\n",
    "\n",
    "    tagged_images = list()\n",
    "    for og_image_idx, og_image in enumerate(og_images):\n",
    "        img_name, _ = os.path.splitext(og_image)\n",
    "        img_name = img_name if img_name[0].isalpha() else int(img_name)\n",
    "        real_name = find_image_name(data['images'], img_name) #Find the real image name from where the crops where made\n",
    "        bboxes_coco =  get_cells_bbox(data, img_name) #Get all bboxes_coco from the tagged images\n",
    "        if len(bboxes_coco) == 0:\n",
    "            if first_pass:\n",
    "                print(f\"skipping {og_image} ({real_name}), no tags.\")\n",
    "            continue\n",
    "        if not first_pass:\n",
    "            tagged_images.append(og_image)\n",
    "\n",
    "        images = sorted([crop for crop in crops if crop.startswith(real_name)]) #Get all the crops from that image\n",
    "        df = pd.read_csv(os.path.join(CSV_PATH, f\"{real_name}.csv\")) #Read the csv of that image\n",
    "        bboxes_sam = [tuple(map(int, row)) for row in df[['x', 'y', 'w', 'h']].values]\n",
    "        df = df.rename(columns={'cell_id': 'cell_id_sam'})\n",
    "\n",
    "        batch_size=30\n",
    "        for idx, batch in process_images_in_batches(images, batch_size=batch_size): #Read the images in batch_size batches\n",
    "            print(f\"Model: {model} ({model_idx+1}/{len(models)}) - Image: {og_image} ({og_image_idx+1}/{len(og_images)}) - Batch {idx}/{math.ceil(len(images)/batch_size)}\", end='\\r')\n",
    "\n",
    "            batch_prediction = predict_cell(loaded_model,model, image_path=CROPS_PATH, images_batch=batch, color_type=color_type)\n",
    "\n",
    "            # is_cell = [True if sublist[0] >= 0.5 else False for sublist in batch_prediction]\n",
    "            # is_cell = [True if np.argmax(sublist[0]) == 0 else False for sublist in batch_prediction]\n",
    "\n",
    "            is_cell = 1-np.argmax(batch_prediction, axis=1).astype(bool)\n",
    "\n",
    "            # For each image in the batch store the prediction in the csv toghether with the cell_id of the coco tags\n",
    "            for idx, i in enumerate(batch):\n",
    "                crop_name, _ = os.path.splitext(i)\n",
    "                cell_id = crop_name.split('_')[2]\n",
    "\n",
    "                mask = (df['cell_id_sam'] == int(cell_id)) & (df['image'] == real_name + \".jpg\")\n",
    "                filtered_df = df[mask]\n",
    "\n",
    "                df.loc[mask, 'is_cell_sam'] = is_cell[idx]\n",
    "                df.loc[mask, 'image'] = img_name\n",
    "                x, y, w, h = filtered_df[['x', 'y', 'w', 'h']].values[0]\n",
    "                intercept, cell_id_coco = bbox_intercept((x,y,w,h), bboxes_coco,0.75)\n",
    "                df.loc[mask, 'cell_id_coco'] = int(cell_id_coco)\n",
    "                df.loc[mask, 'is_cell_ground_truth'] = intercept\n",
    "\n",
    "        #For each cell in coco i check if it was not detected by sam\n",
    "        for idx, bbox_coco in enumerate(bboxes_coco):\n",
    "            intercept, _ = bbox_intercept(bbox_coco, bboxes_sam)\n",
    "            if not intercept:\n",
    "                new_row = {'area': 0,'x':bbox_coco[0] ,'y':bbox_coco[1],'w':bbox_coco[2],'h':bbox_coco[3],\n",
    "                            'bbox_area':bbox_coco[2]*bbox_coco[3],'image':img_name,'cell_id_sam':-1,\n",
    "                            'is_cell_sam':False,'cell_id_coco':idx,'is_cell_ground_truth':True}\n",
    "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Configure the dataframe to store it\n",
    "        df['cell_id_coco'] = df['cell_id_coco'].astype(int)\n",
    "        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "        df.to_csv(os.path.join(output, f\"{img_name}.csv\"))\n",
    "    first_pass = False\n",
    "    print(\"DONE\\n-------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kxl9FrhSK1N5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested images: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tested images: {tagged_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzVi4dRXK1N6"
   },
   "source": [
    "#### Functions testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num=331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8p2aBzMK1N6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lucas/code/LucasMareque/projects/ina_utn/Modelos/evaluated/Copy of model_Encoder_SSIM+MAE0/332.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m models_compare \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy of model_Encoder_SSIM+MAE0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy of model_Encoder_SSIM+MAE1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy of model_Encoder_SSIM+MAE4\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m this_model \u001b[38;5;129;01min\u001b[39;00m models_compare:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_num\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     bboxes_og \u001b[38;5;241m=\u001b[39m  get_cells_bbox(data, img_num)\n\u001b[1;32m      8\u001b[0m     df_cells \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_cell_sam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m]\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lucas/code/LucasMareque/projects/ina_utn/Modelos/evaluated/Copy of model_Encoder_SSIM+MAE0/332.csv'"
     ]
    }
   ],
   "source": [
    "#img_num = int(np.random.choice(tagged_images, 1)[0].split('.')[0])\n",
    "img_num=img_num +1\n",
    "models_compare = [\"Copy of model_Encoder_SSIM+MAE0\", \"Copy of model_Encoder_SSIM+MAE1\", \"Copy of model_Encoder_SSIM+MAE4\"]\n",
    "\n",
    "for this_model in models_compare:\n",
    "    df = pd.read_csv(os.path.join(RESULTS_PATH, \"evaluated\", this_model, f\"{str(img_num)}.csv\"))\n",
    "    bboxes_og =  get_cells_bbox(data, img_num)\n",
    "    df_cells = df.loc[df['is_cell_sam']==True]\n",
    "    bboxes_sam_cells = [tuple(map(int, row)) for row in df_cells[['x', 'y', 'w', 'h']].values]\n",
    "    df_not = df.loc[df['is_cell_sam']==False]\n",
    "    bboxes_sam_not = [tuple(map(int, row)) for row in df_not[['x', 'y', 'w', 'h']].values]\n",
    "    img = cv.imread(os.path.join(IMAGES_PATH, f'{str(img_num)}.png'))\n",
    "\n",
    "    \n",
    "    for bbox in bboxes_og:\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = int(x), int(y)\n",
    "        x2, y2 = int(x + w), int(y + h)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 10)\n",
    "\n",
    "    for bbox in bboxes_sam_cells:\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = int(x), int(y)\n",
    "        x2, y2 = int(x + w), int(y + h)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "    \n",
    "    for bbox in bboxes_sam_not:\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = int(x), int(y)\n",
    "        x2, y2 = int(x + w), int(y + h)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 3)\n",
    "    \n",
    "    for bbox_sam in bboxes_sam_cells:\n",
    "        for bbox_og in bboxes_og:\n",
    "            # if bb_overlap_percentage(bbox_sam, bbox_og) >= 0.2:\n",
    "            # if bbox_fully_contained(bbox_sam, bbox_og):\n",
    "            if bbox_fully_contained(bbox_sam, bbox_og) or bb_overlap_percentage(bbox_sam, bbox_og) >= 0.75:\n",
    "                # x, y, w, h = bbox_og\n",
    "                x, y, w, h = bbox_sam\n",
    "                x1, y1 = int(x), int(y)\n",
    "                x2, y2 = int(x + w), int(y + h)\n",
    "                cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"IMAGE: {img_num}\\nMODEL: {this_model}\\nRed: COCO Reference  --- Black : Not Cell classification\\nBlue : Cell classification --- Green : Match COCO-Classifier\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cELtt2e5K1N7"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UfS2kM8K1N8"
   },
   "outputs": [],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    #output = os.path.join(RESULTS_PATH, base_model)\n",
    "    #if not os.path.exists(output):\n",
    "    #    continue\n",
    "    for og_image_idx, og_image in enumerate(og_images):\n",
    "        df = pd.read_csv(os.path.join(output, f\"{img_name}.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dmIBgn3HE0xO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>bbox_area</th>\n",
       "      <th>image</th>\n",
       "      <th>cell_id_sam</th>\n",
       "      <th>is_cell_sam</th>\n",
       "      <th>cell_id_coco</th>\n",
       "      <th>is_cell_ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37780</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>46056.0</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23443</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>57410</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>76874.0</td>\n",
       "      <td>392</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50978</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>62835.0</td>\n",
       "      <td>392</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26447</td>\n",
       "      <td>928.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>33488.0</td>\n",
       "      <td>392</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>123284.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>48867.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>64090.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>64602.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>468450.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   area       x       y       w      h  bbox_area  image  \\\n",
       "0             0  37780    80.0  1819.0   202.0  228.0    46056.0    392   \n",
       "1             1  23443  1542.0  1927.0   250.0  120.0    30000.0    392   \n",
       "2             2  57410  1238.0  1032.0   266.0  289.0    76874.0    392   \n",
       "3             3  50978  1020.0  1089.0   213.0  295.0    62835.0    392   \n",
       "4             4  26447   928.0   809.0   182.0  184.0    33488.0    392   \n",
       "..          ...    ...     ...     ...     ...    ...        ...    ...   \n",
       "247         247      0  2464.0    49.0   476.0  259.0   123284.0    392   \n",
       "248         248      0  2099.0   703.0   273.0  179.0    48867.0    392   \n",
       "249         249      0  2345.0   684.0   377.0  170.0    64090.0    392   \n",
       "250         250      0  2780.0   771.0   291.0  222.0    64602.0    392   \n",
       "251         251      0  1826.0   685.0  1041.0  450.0   468450.0    392   \n",
       "\n",
       "     cell_id_sam  is_cell_sam  cell_id_coco  is_cell_ground_truth  \n",
       "0              0          1.0            30                  True  \n",
       "1              1          0.0            43                  True  \n",
       "2              2          1.0            39                  True  \n",
       "3              3          1.0            38                  True  \n",
       "4              4          0.0            -1                 False  \n",
       "..           ...          ...           ...                   ...  \n",
       "247           -1          0.0            66                  True  \n",
       "248           -1          0.0            68                  True  \n",
       "249           -1          0.0            69                  True  \n",
       "250           -1          0.0            70                  True  \n",
       "251           -1          0.0            71                  True  \n",
       "\n",
       "[252 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
