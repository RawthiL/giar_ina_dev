{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NM_bkf-K1Nm"
   },
   "source": [
    "## Classify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbLDGkpsK1Np"
   },
   "source": [
    "### Useful links\n",
    "\n",
    "#### <u>Datasets</u>\n",
    "Complete dataset: The full dataset of images used can be found [here](https://drive.google.com/drive/folders/1Rz0JrjUCU-4VmDkolbkwUcM8xW1jd9pl?usp=drive_link)\n",
    "\n",
    "Cropped datasets: The complete dataset has been used by SAM to create segmentations of cells, with some noise, resulting in:\n",
    " All these [crops](https://drive.google.com/drive/folders/1Rz0JrjUCU-4VmDkolbkwUcM8xW1jd9pl?usp=drive_link)\n",
    " and all these [csv files](https://frbautneduar-my.sharepoint.com/:u:/g/personal/ntaurozzi_frba_utn_edu_ar/EYKi5F-wXGRNkAqjPSRVhvUByTsnsEB10OrZiJHclkOPWQ?e=tVwmkS) with the information of each crop.\n",
    "\n",
    "Input/Target dataset: From the complete dataset, some images have been tagged by the biologists an those 58 (for now) can be found [here](https://frbautneduar-my.sharepoint.com/:u:/g/personal/ntaurozzi_frba_utn_edu_ar/EQbvUOwADihJsJLAyVfBdYwBDvHJDMS5GQuyyP_PzUeCLQ?e=z8A7Tn) each image with its corresponding target. The name of the images here are ids given to them by a json file.\n",
    "\n",
    "#### <u>Auxiliary files</u>\n",
    "To create the input/target dataset from the complete dataset, this [json](https://drive.google.com/file/d/1ydQ2fIOllwPPU64Kneda4mVidUww1X9T/view?usp=drive_link) was used\n",
    "\n",
    "#### <u>Models</u>\n",
    "For making the predictions these [models](https://frbautneduar-my.sharepoint.com/:f:/g/personal/lmareque_frba_utn_edu_ar/EiDo8WYptOpEiyzJHhQIbwoBUAfsoULwRRKEm-fmgzQD-g?e=6TE9yu) will be used\n",
    "\n",
    "### Code walkthrough\n",
    "\n",
    "This notebook will process all the images from the input/target dataset. It will use the json file to map the IDs to their original filenames. Then, it will search for all the crops belonging to these images and use all the models to predict whether each crop is noise or a cell. After the prediction, it will store the results in the corresponding CSV file for each image.\n",
    "\n",
    "The output will be a folder for each model used. Within each folder, a CSV file will be created for each image, containing information about the bounding boxes of each crop and its classification (cell or noise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D9wKHvSK1Nr"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8444,
     "status": "ok",
     "timestamp": 1739547543305,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "Qh0_ITlO0ATe",
    "outputId": "60991a2c-7091-49de-db51-8e941131e3f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 10:22:21.817013: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-26 10:22:21.888653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745673741.914749    7595 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745673741.922170    7595 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745673741.967863    7595 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745673741.967872    7595 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745673741.967873    7595 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745673741.967874    7595 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-26 10:22:21.974252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "import math\n",
    "import keras\n",
    "import cv2 as cv\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import efficientnet_v2,convnext\n",
    "#sys.path.insert(0, \"../packages/python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAIP2PV8K1Nv"
   },
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nicolas/Documentos/UTN/INA/giar_ina_dev/notebooks/result_analysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739547543305,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "B0FEJeKWK1Nx"
   },
   "outputs": [],
   "source": [
    "CSV_PATH = '../../output/data/'\n",
    "CROPS_PATH = '../../output/cropped_cells_full/'\n",
    "MODELS_PATH = '../../models/'\n",
    "IMAGES_PATH = '../../media/data/input/'\n",
    "JSON_PATH = '../../media/corte-27-02-2024.json'\n",
    "OUTPUT_PATH = '../../output/'\n",
    "\n",
    "# CSV_PATH = '/home/lucas/code/LucasMareque/projects/ina_utn/datasets/Abril2023/sam_uploaded_out'\n",
    "# CROPS_PATH = '/home/lucas/code/LucasMareque/projects/ina_utn/datasets/Abril2023/cropped_cells_original'\n",
    "# MODELS_PATH = '/home/lucas/code/LucasMareque/projects/ina_utn/Modelos/Best_models'\n",
    "# IMAGES_PATH = '/home/lucas/code/LucasMareque/projects/ina_utn/datasets/Abril2023/raw_dataset/input'\n",
    "# JSON_PATH = '/home/lucas/code/LucasMareque/projects/ina_utn/datasets/Abril2023/corte-27-02-2024.json'\n",
    "\n",
    "\n",
    "OUTPUT_PATH = '/home/lucas/code/LucasMareque/projects/ina_utn/Modelos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EE4Qd1GyK1Nz"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739547543305,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "ll9lWzhHK1N0"
   },
   "outputs": [],
   "source": [
    "def predict_cell(model,model_name, image_path, images_batch, color_type):\n",
    "  \"\"\"\n",
    "  Given an image batch it returns the predictions of the batch with the given model.\n",
    "\n",
    "  Args:\n",
    "    model: keras model to use.\n",
    "    image_path: path to the folder where the images are.\n",
    "    images_batch: list of the image names to include in the batch\n",
    "\n",
    "  Returns:\n",
    "    A list of predictions.\n",
    "  \"\"\"\n",
    "\n",
    "  images = []\n",
    "  for image in images_batch:\n",
    "      img = cv.imread(os.path.join(image_path,image), color_type)\n",
    "\n",
    "      if model_name == 'model_EfficientNetB0.keras':\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, (224, 224))\n",
    "        img = efficientnet_v2.preprocess_input(img)\n",
    "        images.append(img)\n",
    "\n",
    "      elif model_name == \"model_ConvNeXtTiny.keras\":\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, (224, 224))\n",
    "        img = convnext.preprocess_input(img)\n",
    "        images.append(img)\n",
    "\n",
    "      else:\n",
    "        img = cv.resize(img, (128, 128))\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "\n",
    "\n",
    "  batch = np.stack(images)\n",
    "  if color_type == cv.IMREAD_GRAYSCALE:\\\n",
    "    # Add missing channel\n",
    "    batch = np.expand_dims(batch, axis=-1).astype(np.float32)\n",
    "\n",
    "  prediction = model.predict(batch, verbose=0)\n",
    "  prediction = tf.nn.softmax(prediction, axis=-1)\n",
    "  return prediction\n",
    "\n",
    "\n",
    "def find_image_name(data, id):\n",
    "  \"\"\"\n",
    "  Given a list of objects it searches the file_name from the id.\n",
    "\n",
    "  Args:\n",
    "    data: list of objects to search from.\n",
    "    id: id of the file name to return.\n",
    "\n",
    "  Returns:\n",
    "    The file name of the image id.\n",
    "  \"\"\"\n",
    "  for img in data:\n",
    "      if img['id'] == id:\n",
    "          base_name, _ = os.path.splitext(img['file_name'])\n",
    "          return base_name\n",
    "\n",
    "def get_cells_bbox(data, id):\n",
    "  \"\"\"\n",
    "  Given a list of objects it returns a list of bounding boxes for the given id.\n",
    "\n",
    "  Args:\n",
    "    data: list of objects to search from.\n",
    "    id: id of the objetct to search.\n",
    "\n",
    "  Returns:\n",
    "    A list of bounding boxes.\n",
    "  \"\"\"\n",
    "  return [cell['bbox'] for cell in data['annotations'] if cell['image_id'] == id]\n",
    "\n",
    "def process_images_in_batches(string_list, batch_size=10):\n",
    "  \"\"\"\n",
    "  Processes a list of strings in batches of a specified size.\n",
    "\n",
    "  Args:\n",
    "    string_list: The list of strings to process.\n",
    "    batch_size: The size of each batch.\n",
    "\n",
    "  Yields:\n",
    "    A batch of strings.\n",
    "  \"\"\"\n",
    "  for i in range(0, len(string_list), batch_size):\n",
    "    batch_num = i // batch_size + 1  # Calculate batch number (1-indexed)\n",
    "    yield batch_num, string_list[i:i + batch_size]\n",
    "\n",
    "def bb_overlap_percentage(box1, box2):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) of two bounding boxes using Shapely.\n",
    "\n",
    "    Args:\n",
    "        box1: A tuple or list containing (x1, y1, width, height) of the first bounding box.\n",
    "        box2: A tuple or list containing (x1, y1, width, height) of the second bounding box.\n",
    "\n",
    "    Returns:\n",
    "        The IoU value, a float between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate box coordinates\n",
    "    x1_min, y1_min, width1, height1 = box1\n",
    "    x1_max = x1_min + width1\n",
    "    y1_max = y1_min + height1\n",
    "    x2_min, y2_min, width2, height2 = box2\n",
    "    x2_max = x2_min + width2\n",
    "    y2_max = y2_min + height2\n",
    "\n",
    "    # Create polygons\n",
    "    poly1 = Polygon([(x1_min, y1_min), (x1_max, y1_min), (x1_max, y1_max), (x1_min, y1_max)])\n",
    "    poly2 = Polygon([(x2_min, y2_min), (x2_max, y2_min), (x2_max, y2_max), (x2_min, y2_max)])\n",
    "\n",
    "    # Calculate intersection and union areas\n",
    "    intersection = poly1.intersection(poly2).area\n",
    "    union = poly1.union(poly2).area\n",
    "\n",
    "    #print(poly1.area, poly2.area, intersection)\n",
    "\n",
    "    return intersection / poly1.area if union > 0 else 0.0\n",
    "\n",
    "def bbox_fully_contained(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Checks if bounding box 1 is fully contained within bounding box 2.\n",
    "\n",
    "    Args:\n",
    "        bbox1: A tuple (x1, y1, width1, height1) representing the first bounding box.\n",
    "        bbox2: A tuple (x2, y2, width2, height2) representing the second bounding box.\n",
    "\n",
    "    Returns:\n",
    "        True if bbox1 is fully contained within bbox2, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate coordinates of bounding boxes\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "    bbox1_coords = [(x1, y1), (x1 + w1, y1), (x1 + w1, y1 + h1), (x1, y1 + h1)]\n",
    "    bbox2_coords = [(x2, y2), (x2 + w2, y2), (x2 + w2, y2 + h2), (x2, y2 + h2)]\n",
    "\n",
    "    # Create Shapely polygons\n",
    "    poly1 = Polygon(bbox1_coords)\n",
    "    poly2 = Polygon(bbox2_coords)\n",
    "\n",
    "    # Check if bbox1 is fully contained within bbox2\n",
    "    return poly1.within(poly2)\n",
    "\n",
    "def bbox_intercept(bbox, bbox_list, threshold=0):\n",
    "  for idx, bbox_target in enumerate(bbox_list):\n",
    "    if threshold > 0: # 0.75\n",
    "      iou = bb_overlap_percentage(bbox, bbox_target)\n",
    "      if iou >= threshold:\n",
    "        return True, idx\n",
    "\n",
    "    else:\n",
    "      contained = bbox_fully_contained(bbox, bbox_target)\n",
    "      if contained:\n",
    "        return True, idx\n",
    "\n",
    "  return False, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJrUWrmRK1N1"
   },
   "source": [
    "### Lists of elements to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1739547544811,
     "user": {
      "displayName": "Lucas Mareque",
      "userId": "07409948060440606420"
     },
     "user_tz": 180
    },
    "id": "2_N4rhrPK1N3"
   },
   "outputs": [],
   "source": [
    "csvs = sorted(os.listdir(CSV_PATH)) #Paths to the csv of SAM detections of each image\n",
    "crops = sorted(os.listdir(CROPS_PATH)) #Paths to the crops made from SAM detection of the full_images\n",
    "models = sorted(os.listdir(MODELS_PATH))[1] #Models to use in the prediction\n",
    "og_images = sorted(os.listdir(IMAGES_PATH)) #full_images from where the crops are made\n",
    "with open(JSON_PATH, 'r') as f: #json with the information of the filename of the images\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_Encoder_SSIM+MAE0 (1).keras'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPig-pjZK1N4"
   },
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5u0zY-ffK1N4",
    "outputId": "82ab7cbd-7d44-4e4c-a9fb-cd1609b516e0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Copy of model_Encoder_SSIM+MAE0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:51:01.054874: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Copy of model_Encoder_SSIM+MAE0.keras (1/6) - Image: 331.png (1/58) - Batch 1/5\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743105061.809745   13679 service.cc:148] XLA service 0x7fd5b000f770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743105061.809797   13679 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "2025-03-27 16:51:01.820443: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743105061.965944   13679 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONEl: Copy of model_Encoder_SSIM+MAE0.keras (1/6) - Image: 392.png (58/58) - Batch 7/7\n",
      "-------------------------------------------------------------------------------------------\n",
      "Testing model Copy of model_Encoder_SSIM+MAE1\n",
      "DONEl: Copy of model_Encoder_SSIM+MAE1.keras (3/6) - Image: 392.png (58/58) - Batch 7/7\n",
      "-------------------------------------------------------------------------------------------\n",
      "Testing model Copy of model_Encoder_SSIM+MAE4\n",
      "DONEl: Copy of model_Encoder_SSIM+MAE4.keras (5/6) - Image: 392.png (58/58) - Batch 7/7\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "first_pass = True\n",
    "for model_idx, model in enumerate(models):\n",
    "\n",
    "\n",
    "    base_model, ext = os.path.splitext(model)\n",
    "    if '.keras' != ext:\n",
    "        continue\n",
    "    print(f'Testing model {base_model.split(\".\")[0]}')\n",
    "\n",
    "    model_path=os.path.join(MODELS_PATH, model)\n",
    "    loaded_model = keras.models.load_model(model_path)\n",
    "\n",
    "    if loaded_model.input.shape[-1] == 1:\n",
    "        color_type = cv.IMREAD_GRAYSCALE\n",
    "    else:\n",
    "        color_type = cv.IMREAD_COLOR\n",
    "\n",
    "\n",
    "    output = os.path.join(OUTPUT_PATH, \"evaluated\", base_model)\n",
    "\n",
    "    if not os.path.exists(output): #Create dirs for each model used\n",
    "        os.makedirs(output)\n",
    "\n",
    "    tagged_images = list()\n",
    "    for og_image_idx, og_image in enumerate(og_images):\n",
    "        img_name, _ = os.path.splitext(og_image)\n",
    "        real_name = find_image_name(data['images'], int(img_name)) #Find the real image name from where the crops where made\n",
    "        bboxes_coco =  get_cells_bbox(data, int(img_name)) #Get all bboxes_coco from the tagged images\n",
    "        if len(bboxes_coco) == 0:\n",
    "            if first_pass:\n",
    "                print(f\"skipping {og_image} ({real_name}), no tags.\")\n",
    "            continue\n",
    "        if not first_pass:\n",
    "            tagged_images.append(og_image)\n",
    "\n",
    "        images = sorted([crop for crop in crops if crop.startswith(real_name)]) #Get all the crops from that image\n",
    "        df = pd.read_csv(os.path.join(CSV_PATH, f\"{real_name}.csv\")) #Read the csv of that image\n",
    "        bboxes_sam = [tuple(map(int, row)) for row in df[['x', 'y', 'w', 'h']].values]\n",
    "        df = df.rename(columns={'cell_id': 'cell_id_sam'})\n",
    "\n",
    "        batch_size=30\n",
    "        for idx, batch in process_images_in_batches(images, batch_size=batch_size): #Read the images in batch_size batches\n",
    "            print(f\"Model: {model} ({model_idx+1}/{len(models)}) - Image: {og_image} ({og_image_idx+1}/{len(og_images)}) - Batch {idx}/{math.ceil(len(images)/batch_size)}\", end='\\r')\n",
    "\n",
    "            batch_prediction = predict_cell(loaded_model,model, image_path=CROPS_PATH, images_batch=batch, color_type=color_type)\n",
    "\n",
    "            # is_cell = [True if sublist[0] >= 0.5 else False for sublist in batch_prediction]\n",
    "            # is_cell = [True if np.argmax(sublist[0]) == 0 else False for sublist in batch_prediction]\n",
    "\n",
    "            is_cell = 1-np.argmax(batch_prediction, axis=1).astype(bool)\n",
    "\n",
    "            # For each image in the batch store the prediction in the csv toghether with the cell_id of the coco tags\n",
    "            for idx, i in enumerate(batch):\n",
    "                crop_name, _ = os.path.splitext(i)\n",
    "                cell_id = crop_name.split('_')[2]\n",
    "\n",
    "                mask = (df['cell_id_sam'] == int(cell_id)) & (df['image'] == real_name + \".jpg\")\n",
    "                filtered_df = df[mask]\n",
    "\n",
    "                df.loc[mask, 'is_cell_sam'] = is_cell[idx]\n",
    "                df.loc[mask, 'image'] = img_name\n",
    "                x, y, w, h = filtered_df[['x', 'y', 'w', 'h']].values[0]\n",
    "                intercept, cell_id_coco = bbox_intercept((x,y,w,h), bboxes_coco,0.75)\n",
    "                df.loc[mask, 'cell_id_coco'] = int(cell_id_coco)\n",
    "                df.loc[mask, 'is_cell_ground_truth'] = intercept\n",
    "\n",
    "        #For each cell in coco i check if it was not detected by sam\n",
    "        for idx, bbox_coco in enumerate(bboxes_coco):\n",
    "            intercept, _ = bbox_intercept(bbox_coco, bboxes_sam)\n",
    "            if not intercept:\n",
    "                new_row = {'area': 0,'x':bbox_coco[0] ,'y':bbox_coco[1],'w':bbox_coco[2],'h':bbox_coco[3],\n",
    "                            'bbox_area':bbox_coco[2]*bbox_coco[3],'image':img_name,'cell_id_sam':-1,\n",
    "                            'is_cell_sam':False,'cell_id_coco':idx,'is_cell_ground_truth':True}\n",
    "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Configure the dataframe to store it\n",
    "        df['cell_id_coco'] = df['cell_id_coco'].astype(int)\n",
    "        df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "        df.to_csv(os.path.join(output, f\"{img_name}.csv\"))\n",
    "    first_pass = False\n",
    "    print(\"DONE\\n-------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kxl9FrhSK1N5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested images: ['331.png', '332.png', '333.png', '334.png', '335.png', '336.png', '337.png', '341.png', '342.png', '343.png', '344.png', '345.png', '346.png', '347.png', '348.png', '349.png', '350.png', '351.png', '352.png', '353.png', '354.png', '355.png', '356.png', '357.png', '358.png', '359.png', '360.png', '361.png', '362.png', '363.png', '364.png', '365.png', '366.png', '367.png', '368.png', '369.png', '370.png', '371.png', '372.png', '373.png', '374.png', '375.png', '376.png', '377.png', '378.png', '379.png', '380.png', '381.png', '382.png', '383.png', '384.png', '385.png', '386.png', '387.png', '389.png', '390.png', '391.png', '392.png']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tested images: {tagged_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzVi4dRXK1N6"
   },
   "source": [
    "#### Functions testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num=331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s8p2aBzMK1N6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lucas/code/LucasMareque/projects/ina_utn/Modelos/evaluated/Copy of model_Encoder_SSIM+MAE0/332.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m models_compare \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy of model_Encoder_SSIM+MAE0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy of model_Encoder_SSIM+MAE1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy of model_Encoder_SSIM+MAE4\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m this_model \u001b[38;5;129;01min\u001b[39;00m models_compare:\n\u001b[0;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_num\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     bboxes_og \u001b[38;5;241m=\u001b[39m  get_cells_bbox(data, img_num)\n\u001b[1;32m      8\u001b[0m     df_cells \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_cell_sam\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m]\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documentos/UTN/INA/giar_ina_dev/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lucas/code/LucasMareque/projects/ina_utn/Modelos/evaluated/Copy of model_Encoder_SSIM+MAE0/332.csv'"
     ]
    }
   ],
   "source": [
    "#img_num = int(np.random.choice(tagged_images, 1)[0].split('.')[0])\n",
    "img_num=img_num +1\n",
    "models_compare = [\"Copy of model_Encoder_SSIM+MAE0\", \"Copy of model_Encoder_SSIM+MAE1\", \"Copy of model_Encoder_SSIM+MAE4\"]\n",
    "\n",
    "for this_model in models_compare:\n",
    "    df = pd.read_csv(os.path.join(OUTPUT_PATH, \"evaluated\", this_model, f\"{str(img_num)}.csv\"))\n",
    "    bboxes_og =  get_cells_bbox(data, img_num)\n",
    "    df_cells = df.loc[df['is_cell_sam']==True]\n",
    "    bboxes_sam_cells = [tuple(map(int, row)) for row in df_cells[['x', 'y', 'w', 'h']].values]\n",
    "    df_not = df.loc[df['is_cell_sam']==False]\n",
    "    bboxes_sam_not = [tuple(map(int, row)) for row in df_not[['x', 'y', 'w', 'h']].values]\n",
    "    img = cv.imread(os.path.join(IMAGES_PATH, f'{str(img_num)}.png'))\n",
    "\n",
    "    \n",
    "    for bbox in bboxes_og:\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = int(x), int(y)\n",
    "        x2, y2 = int(x + w), int(y + h)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 10)\n",
    "\n",
    "    for bbox in bboxes_sam_cells:\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = int(x), int(y)\n",
    "        x2, y2 = int(x + w), int(y + h)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "    \n",
    "    for bbox in bboxes_sam_not:\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = int(x), int(y)\n",
    "        x2, y2 = int(x + w), int(y + h)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), (0, 0, 0), 3)\n",
    "    \n",
    "    for bbox_sam in bboxes_sam_cells:\n",
    "        for bbox_og in bboxes_og:\n",
    "            # if bb_overlap_percentage(bbox_sam, bbox_og) >= 0.2:\n",
    "            # if bbox_fully_contained(bbox_sam, bbox_og):\n",
    "            if bbox_fully_contained(bbox_sam, bbox_og) or bb_overlap_percentage(bbox_sam, bbox_og) >= 0.75:\n",
    "                # x, y, w, h = bbox_og\n",
    "                x, y, w, h = bbox_sam\n",
    "                x1, y1 = int(x), int(y)\n",
    "                x2, y2 = int(x + w), int(y + h)\n",
    "                cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"IMAGE: {img_num}\\nMODEL: {this_model}\\nRed: COCO Reference  --- Black : Not Cell classification\\nBlue : Cell classification --- Green : Match COCO-Classifier\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cELtt2e5K1N7"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1UfS2kM8K1N8"
   },
   "outputs": [],
   "source": [
    "for model_idx, model in enumerate(models):\n",
    "    #output = os.path.join(OUTPUT_PATH, base_model)\n",
    "    #if not os.path.exists(output):\n",
    "    #    continue\n",
    "    for og_image_idx, og_image in enumerate(og_images):\n",
    "        df = pd.read_csv(os.path.join(output, f\"{img_name}.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dmIBgn3HE0xO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>bbox_area</th>\n",
       "      <th>image</th>\n",
       "      <th>cell_id_sam</th>\n",
       "      <th>is_cell_sam</th>\n",
       "      <th>cell_id_coco</th>\n",
       "      <th>is_cell_ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37780</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>46056.0</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23443</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>57410</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>76874.0</td>\n",
       "      <td>392</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50978</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>62835.0</td>\n",
       "      <td>392</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26447</td>\n",
       "      <td>928.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>33488.0</td>\n",
       "      <td>392</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>123284.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>48867.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>64090.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>64602.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>468450.0</td>\n",
       "      <td>392</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   area       x       y       w      h  bbox_area  image  \\\n",
       "0             0  37780    80.0  1819.0   202.0  228.0    46056.0    392   \n",
       "1             1  23443  1542.0  1927.0   250.0  120.0    30000.0    392   \n",
       "2             2  57410  1238.0  1032.0   266.0  289.0    76874.0    392   \n",
       "3             3  50978  1020.0  1089.0   213.0  295.0    62835.0    392   \n",
       "4             4  26447   928.0   809.0   182.0  184.0    33488.0    392   \n",
       "..          ...    ...     ...     ...     ...    ...        ...    ...   \n",
       "247         247      0  2464.0    49.0   476.0  259.0   123284.0    392   \n",
       "248         248      0  2099.0   703.0   273.0  179.0    48867.0    392   \n",
       "249         249      0  2345.0   684.0   377.0  170.0    64090.0    392   \n",
       "250         250      0  2780.0   771.0   291.0  222.0    64602.0    392   \n",
       "251         251      0  1826.0   685.0  1041.0  450.0   468450.0    392   \n",
       "\n",
       "     cell_id_sam  is_cell_sam  cell_id_coco  is_cell_ground_truth  \n",
       "0              0          1.0            30                  True  \n",
       "1              1          0.0            43                  True  \n",
       "2              2          1.0            39                  True  \n",
       "3              3          1.0            38                  True  \n",
       "4              4          0.0            -1                 False  \n",
       "..           ...          ...           ...                   ...  \n",
       "247           -1          0.0            66                  True  \n",
       "248           -1          0.0            68                  True  \n",
       "249           -1          0.0            69                  True  \n",
       "250           -1          0.0            70                  True  \n",
       "251           -1          0.0            71                  True  \n",
       "\n",
       "[252 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
